<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Required meta tags always come first -->
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Research Proposal Part 4: Writing the Review of Releated Literature | Lost Packets
</title>
  <link rel="canonical" href="./research-proposal-part-4-writing-the-review-of-releated-literature.html">

  <link rel="alternate" type="application/atom+xml" href="https://srg-ics-uplb.github.io/blog/feeds/all.atom.xml" title="Full Atom Feed">
  <link rel="alternate" type="application/atom+xml" href="https://srg-ics-uplb.github.io/blog/feeds/{slug}.atom.xml" title="Categories Atom Feed">


  <link rel="stylesheet" href="./theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="./theme/css/font-awesome.min.css">
  <link rel="stylesheet" href="./theme/css/pygments/default.min.css">
  <link rel="stylesheet" href="./theme/css/style.css">


<meta name="description" content="Purpose of the Review of Related Literature Section The review of related literature section serves to: Position your research: Show how your work builds on or differs from existing studies. Highlight the gap: Clearly articulate how existing solutions fall short, justifying your proposed research. Demonstrate expertise: Prove your familiarity with …">
</head>

<body>
  <header class="header">
    <div class="container">
      <div class="row">
        <div class="col-sm-12">
          <h1 class="title"><a href=".">Lost Packets</a></h1>
        </div>
      </div>
    </div>
  </header>

  <div class="main">
    <div class="container">
      <h1>Research Proposal Part 4: Writing the Review of Releated Literature
</h1>
      <hr>
<article class="article">
  <header>
    <ul class="list-inline">
      <li class="list-inline-item text-muted" title="2025-07-24T00:00:00+08:00">
        <i class="fa fa-clock-o"></i>
        Created: Thu 24 July 2025
      </li>

      <li class="list-inline-item">
        <i class="fa fa-folder-open-o"></i>
        <a href="./category/research.html">Research</a>
      </li>
      <li class="list-inline-item">
        <i class="fa fa-user-o"></i>
        <a href="./author/joseph-anthony-c-hermocilla.html">Joseph Anthony C. Hermocilla</a>      </li>
    </ul>
  </header>
  <div class="content">
    <div class="section" id="purpose-of-the-review-of-related-literature-section">
<h2>Purpose of the Review of Related Literature Section</h2>
<p>The review of related literature section serves to:</p>
<ul class="simple">
<li><strong>Position your research</strong>: Show how your work builds on or differs from existing studies.</li>
<li><strong>Highlight the gap</strong>: Clearly articulate how existing solutions fall short, justifying your proposed research.</li>
<li><strong>Demonstrate expertise</strong>: Prove your familiarity with the state-of-the-art in Computer Systems, particularly in Kubernetes, scheduling, and ML workloads for our running example.</li>
<li><strong>Provide context</strong>: For our running example, help readers understand the landscape of scheduling in heterogeneous systems.</li>
</ul>
</div>
<div class="section" id="guidelines-for-writing-the-review">
<h2>Guidelines for Writing the Review</h2>
<p>Specifics are for our running example.</p>
<ol class="arabic simple">
<li><strong>Organize by Themes or Categories</strong>: Group related work into logical categories (e.g., general Kubernetes scheduling, heterogeneous systems, ML workload optimization) to make the review structured and easy to follow.</li>
<li><strong>Focus on Relevance</strong>: Prioritize papers directly related to Kubernetes scheduling, heterogeneous hardware, and ML workloads. Include seminal works and recent advancements (within the last 3-5 years, i.e., 2020-2025).</li>
<li><strong>Critically Analyze</strong>: For each work, summarize its contributions, strengths, and limitations, <em>explicitly linking limitations to your research gap</em>.</li>
<li><strong>Use Authoritative Sources</strong>: Cite top-tier conference and journal papers (e.g., OSDI, SOSP, NSDI, EuroSys, ASPLOS) and relevant industry whitepapers or open-source documentation.</li>
<li><strong>Be Concise and Targeted</strong>: Aim for 1-2 paragraphs per category, focusing on key works (6-10 papers total) to avoid overwhelming the reader.</li>
<li><strong>Highlight Your Contribution</strong>: Conclude by summarizing how your work addresses the gaps identified in the literature.</li>
<li><strong>Use Clear Citations</strong>: Follow a consistent citation style (e.g., IEEE, ACM) and include DOIs or URLs for accessibility.</li>
</ol>
</div>
<div class="section" id="practical-steps-for-writing">
<h2>Practical Steps for Writing</h2>
<ol class="arabic simple">
<li><strong>Gather Sources</strong>:<ul>
<li>Search IEEE Xplore, ACM Digital Library, and arXiv for papers on Kubernetes scheduling, heterogeneous systems, and ML workloads (2020-2025).</li>
<li>Check Kubernetes GitHub issues and documentation for practical insights.</li>
<li>Monitor X for recent discussions (e.g., #Kubernetes, #MLSystems) to identify preprints or community critiques.</li>
</ul>
</li>
<li><strong>Organize and Summarize</strong>:<ul>
<li>Create a table or spreadsheet to track papers, their contributions, and limitations.</li>
<li>Group papers into the three categories above (or adjust based on findings).</li>
<li>Summarize each paper in 2-3 sentences, focusing on relevance to your gap.</li>
</ul>
</li>
<li><strong>Draft Critically</strong>:<ul>
<li>For each category, write a paragraph summarizing 2-3 key works, emphasizing their limitations.</li>
<li>Use transitions to connect categories (e.g., &quot;While Kubernetes schedulers address general workloads, they fall short in heterogeneous settings…&quot;).</li>
</ul>
</li>
<li><strong>Synthesize and Conclude</strong>:<ul>
<li>Write a final paragraph that ties the limitations to your research gap and briefly previews your solution.</li>
</ul>
</li>
<li><strong>Revise for Clarity</strong>:<ul>
<li>Ensure technical terms (e.g., pod, accelerator) are defined or clear from context.</li>
<li>Verify citations are complete and follow the required style (e.g., [Author, Conference Year]).</li>
</ul>
</li>
</ol>
</div>
<div class="section" id="review-of-related-literature-example">
<h2>Review of Related Literature Example</h2>
<p>For our running example, the review can be structured into three main subsections, each addressing a relevant aspect of the research gap, followed by a synthesis that ties the discussion to your proposed work. Shown below is a possible structure for the RRL.</p>
<div class="section" id="kubernetes-scheduling-frameworks">
<h3><em>1. Kubernetes Scheduling Frameworks</em></h3>
<p><strong>Objective</strong>: Review existing Kubernetes scheduling mechanisms and their limitations for heterogeneous ML workloads.</p>
<dl class="docutils">
<dt><strong>Example Discussion</strong>:</dt>
<dd><em>Kubernetes, a widely adopted container orchestration platform, uses a default scheduler that employs a two-phase approach: filtering and scoring [Kubernetes Documentation, 2025]. The default scheduler prioritizes general-purpose metrics like CPU and memory availability but does not account for specialized hardware (e.g., GPUs, TPUs) or ML workload characteristics (e.g., data parallelism). Recent work, such as Firmament [Gog et al., SOSP 2019], integrates flow-based scheduling into Kubernetes, improving throughput for general workloads but lacking specific optimizations for heterogeneous accelerators. Similarly, Volcano [Volcano, 2024] supports batch scheduling for ML tasks but struggles with dynamic resource allocation in mixed CPU/GPU/TPU clusters, as noted in its GitHub issue tracker. These limitations highlight the need for a scheduler tailored to heterogeneous ML environments.</em></dd>
</dl>
</div>
<div class="section" id="scheduling-for-heterogeneous-systems">
<h3><em>2. Scheduling for Heterogeneous Systems</em></h3>
<p><strong>Objective</strong>: Analyze scheduling approaches in heterogeneous computing environments beyond Kubernetes.</p>
<dl class="docutils">
<dt><strong>Example Discussion</strong>:</dt>
<dd><em>Scheduling for heterogeneous systems has been explored in contexts like cloud computing and HPC. For instance, Tiresias [Gu et al., NSDI 2020] proposes a GPU cluster scheduler that optimizes for ML training jobs by predicting job duration and prioritizing short tasks. However, Tiresias assumes uniform GPU types and does not address TPU or mixed-accelerator scenarios. Another work, Themis [Mahajan et al., ASPLOS 2021], introduces fairness-aware scheduling for GPU clusters but incurs high overhead in multi-tenant settings with diverse hardware. These approaches, while effective for specific accelerators, do not generalize to Kubernetes clusters with mixed CPU/GPU/TPU nodes, leaving a gap in flexible, hardware-aware scheduling.</em></dd>
</dl>
</div>
<div class="section" id="optimization-for-ml-workloads">
<h3><em>3. Optimization for ML Workloads</em></h3>
<p><strong>Objective</strong>: Examine systems designed for ML workload optimization, focusing on their scheduling limitations.</p>
<dl class="docutils">
<dt><strong>Example Discussion</strong>:</dt>
<dd><em>ML workloads, such as deep learning training and inference, impose unique demands on system resources. Systems like Allox [Kaur et al., EuroSys 2023] optimize resource allocation for ML jobs in cloud environments by modeling workload dependencies but are not integrated with Kubernetes. Similarly, Google's Borg scheduler [Verma et al., EuroSys 2015] supports large-scale ML workloads but is proprietary and not optimized for open-source platforms like Kubernetes. Recent studies [Wang et al., OSDI 2024] highlight that ML workloads on heterogeneous clusters suffer from resource contention and suboptimal placement due to a lack of hardware-aware scheduling policies. This underscores the need for a Kubernetes-native solution tailored to ML workload demands.</em></dd>
</dl>
</div>
<div class="section" id="synthesis-and-gap-identification">
<h3><em>4. Synthesis and Gap Identification</em></h3>
<p><strong>Objective</strong>: Summarize the limitations of existing work and position your research as a solution.</p>
<dl class="docutils">
<dt><strong>Example Discussion</strong>:</dt>
<dd><em>Existing Kubernetes schedulers, such as the default scheduler and Volcano, are designed for general-purpose or batch workloads but lack fine-grained support for heterogeneous hardware and ML-specific requirements. While systems like Tiresias and Themis address GPU scheduling, they do not generalize to mixed CPU/GPU/TPU clusters or integrate with Kubernetes. Furthermore, ML workload optimizations, as seen in Allox, are not designed for containerized environments. Our work addresses these gaps by proposing a Kubernetes scheduler extension that optimizes pod placement for ML workloads on heterogeneous clusters, improving performance, resource utilization, and scalability.</em></dd>
</dl>
</div>
</div>
<div class="section" id="tips-for-computer-systems-context">
<h2>Tips for Computer Systems Context</h2>
<ul class="simple">
<li><strong>Emphasize Systems Metrics</strong>: Discuss how existing works measure performance (e.g., throughput, latency, resource utilization) and where they fall short for ML workloads.</li>
<li><strong>Address Practicality</strong>: Highlight gaps in real-world applicability, especially for open-source platforms like Kubernetes.</li>
<li><strong>Consider Scalability and Robustness</strong>: Note limitations in handling large-scale or failure-prone clusters, as these are critical in systems research.</li>
<li><strong>Stay Current</strong>: Use recent papers (2020-2025) and check preprints on arXiv or discussions on X to ensure your review reflects the latest trends.</li>
</ul>
</div>
<div class="section" id="acknowledgement">
<h2>Acknowledgement</h2>
<p>This article was made with the help of Grok (accessed 2025-07-24)</p>
</div>

  </div>
</article>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
      <div class="row">
       <ul class="col-sm-6 list-inline">
          <li class="list-inline-item"><a href="./authors.html">Authors</a></li>
          <li class="list-inline-item"><a href="./archives.html">Archives</a></li>
          <li class="list-inline-item"><a href="./categories.html">Categories</a></li>
        </ul>
        <p class="col-sm-6 text-sm-right text-muted">
          Generated by <a href="https://github.com/getpelican/pelican" target="_blank">Pelican</a> / <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
        </p>
      </div>
    </div>
  </footer>
</body>

</html>