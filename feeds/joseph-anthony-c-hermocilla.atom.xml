<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Lost Packets - Joseph Anthony C. Hermocilla</title><link href="https://srg-ics-uplb.github.io/blog/" rel="alternate"></link><link href="https://srg-ics-uplb.github.io/blog/feeds/joseph-anthony-c-hermocilla.atom.xml" rel="self"></link><id>https://srg-ics-uplb.github.io/blog/</id><updated>2025-07-24T23:00:00+08:00</updated><entry><title>Research Proposal Part 5: Writing the Title</title><link href="https://srg-ics-uplb.github.io/blog/research-proposal-part-5-writing-the-title.html" rel="alternate"></link><published>2025-07-24T23:00:00+08:00</published><updated>2025-07-24T23:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2025-07-24:/blog/research-proposal-part-5-writing-the-title.html</id><summary type="html">&lt;p class="first last"&gt;The title of a research proposal in Computer Systems should be clear, concise, and informative, conveying the key focus, contribution, and scope of the work. It should attract the attention of the target audience (e.g., systems researchers, industry practitioners) while adhering to academic standards.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;The title of a research proposal in Computer Systems should be clear, concise, and informative, conveying the key focus, contribution, and scope of the work. It should attract the attention of the target audience (e.g., systems researchers, industry practitioners) while adhering to academic standards. Below are the key guidelines for crafting an effective title for our running example:&lt;/p&gt;
&lt;div class="section" id="be-clear-and-specific"&gt;
&lt;h2&gt;1. Be Clear and Specific&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Objective&lt;/strong&gt;: Clearly describe the main focus of the research (e.g., Kubernetes scheduling, heterogeneous clusters, ML workloads).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Avoid Ambiguity&lt;/strong&gt;: Use precise terms to indicate the system, problem, or technology (e.g., &amp;quot;Kubernetes scheduler&amp;quot; instead of &amp;quot;orchestration system&amp;quot;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Highlight the Contribution&lt;/strong&gt;: Include the novel aspect (e.g., &amp;quot;extension,&amp;quot; &amp;quot;optimization&amp;quot;) to differentiate from existing work.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="incorporate-key-keywords"&gt;
&lt;h2&gt;2. Incorporate Key Keywords&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Include domain-specific terms to ensure the title is discoverable in academic databases (e.g., IEEE Xplore, ACM Digital Library) and aligns with Computer Systems terminology.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Examples&lt;/strong&gt;: Use terms like &amp;quot;scheduling,&amp;quot; &amp;quot;heterogeneous computing,&amp;quot; &amp;quot;machine learning workloads,&amp;quot; &amp;quot;Kubernetes,&amp;quot; &amp;quot;resource optimization.&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Balance&lt;/strong&gt;: Avoid overloading with jargon; aim for terms that are broadly understood in systems research.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="emphasize-novelty-and-impact"&gt;
&lt;h2&gt;3. Emphasize Novelty and Impact&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Highlight the Gap&lt;/strong&gt;: Suggest how the research addresses an unsolved problem (e.g., &amp;quot;optimized for heterogeneous clusters&amp;quot;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Focus on Outcome&lt;/strong&gt;: Include the intended benefit, such as &amp;quot;improved performance,&amp;quot; &amp;quot;enhanced scalability,&amp;quot; or &amp;quot;efficient resource utilization.&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Systems Focus&lt;/strong&gt;: Emphasize systems-level contributions (e.g., scheduler design, system integration) typical in OSDI, SOSP, or EuroSys papers.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="keep-it-concise"&gt;
&lt;h2&gt;4. Keep It Concise&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Length&lt;/strong&gt;: Aim for 8-15 words to balance detail and brevity, as longer titles may lose impact.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Avoid Redundancy&lt;/strong&gt;: Eliminate unnecessary words (e.g., &amp;quot;A Study on&amp;quot; or &amp;quot;Towards&amp;quot;) unless required by journal/conference guidelines.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clarity Over Creativity&lt;/strong&gt;: Prioritize clarity over catchy phrases, as is standard in systems research.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="align-with-the-problem-statement"&gt;
&lt;h2&gt;5. Align with the Problem Statement&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: Ensure the title reflects the problem statement (e.g., addressing suboptimal scheduling in Kubernetes for ML workloads on heterogeneous clusters).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scope&lt;/strong&gt;: Match the scope of the aim and objectives (e.g., focus on scheduler extension, not general orchestration).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="follow-conference-journal-conventions"&gt;
&lt;h2&gt;6. Follow Conference/Journal Conventions&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Check Guidelines&lt;/strong&gt;: Review target venues (e.g., NSDI, ASPLOS, EuroSys) for title formatting preferences (e.g., capitalization, colons).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Style&lt;/strong&gt;: Use a descriptive or declarative style common in systems papers (e.g., &amp;quot;Optimizing X for Y&amp;quot; or &amp;quot;A System for Z&amp;quot;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Examples from Field&lt;/strong&gt;: Model after titles in top systems conferences, such as &amp;quot;Tiresias: A GPU Cluster Manager for Distributed Deep Learning&amp;quot; [NSDI 2020].&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="test-for-readability-and-appeal"&gt;
&lt;h2&gt;7. Test for Readability and Appeal&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Audience&lt;/strong&gt;: Ensure the title is understandable to systems researchers and practitioners familiar with Kubernetes and ML.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Feedback&lt;/strong&gt;: Share drafts with peers or mentors to confirm clarity and relevance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Searchability&lt;/strong&gt;: Test if the title includes keywords likely to be searched (e.g., &amp;quot;Kubernetes,&amp;quot; &amp;quot;heterogeneous,&amp;quot; &amp;quot;machine learning&amp;quot;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="avoid-overpromising"&gt;
&lt;h2&gt;8. Avoid Overpromising&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Be Realistic&lt;/strong&gt;: Don't claim overly broad impacts (e.g., &amp;quot;Revolutionizing Cloud Computing&amp;quot;) unless justified.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Focus on Contribution&lt;/strong&gt;: Emphasize the specific system or technique (e.g., scheduler extension) rather than vague goals.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="title-example"&gt;
&lt;h3&gt;Title Example&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&amp;quot;Optimizing Kubernetes Scheduling for Machine Learning Workloads on Heterogeneous CPU/GPU/TPU Clusters&amp;quot;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="discussion-of-the-example-title"&gt;
&lt;h2&gt;Discussion of the Example Title&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Clarity and Specificity&lt;/strong&gt;: The title clearly specifies the system (Kubernetes), the component (scheduling), the target application (machine learning workloads), and the context (heterogeneous CPU/GPU/TPU clusters).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Keywords&lt;/strong&gt;: Includes key terms like &amp;quot;Kubernetes,&amp;quot; &amp;quot;scheduling,&amp;quot; &amp;quot;machine learning,&amp;quot; &amp;quot;heterogeneous,&amp;quot; and &amp;quot;CPU/GPU/TPU&amp;quot; for discoverability in systems research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Novelty and Impact&lt;/strong&gt;: &amp;quot;Optimizing&amp;quot; suggests a performance-focused contribution, addressing the gap in inefficient pod placement for ML workloads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conciseness&lt;/strong&gt;: At 10 words, it's brief yet descriptive, fitting within typical systems paper title lengths.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alignment with Problem Statement&lt;/strong&gt;: Reflects the problem statement's focus on suboptimal scheduling in Kubernetes for heterogeneous ML clusters, emphasizing performance and resource utilization.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Systems Convention&lt;/strong&gt;: Follows a descriptive style common in OSDI or NSDI papers (e.g., &amp;quot;Optimizing X for Y&amp;quot;) and avoids vague or overly broad terms.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="alternative-title-examples"&gt;
&lt;h2&gt;Alternative Title Examples&lt;/h2&gt;
&lt;p&gt;To illustrate flexibility, here are variations depending on emphasis:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;More Technical&lt;/strong&gt;: &lt;em&gt;&amp;quot;A Kubernetes Scheduler Extension for Heterogeneous ML Workload Optimization&amp;quot;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Broader Scope&lt;/strong&gt;: &lt;em&gt;&amp;quot;Efficient Scheduling for ML Workloads in Heterogeneous Kubernetes Clusters&amp;quot;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Specific Metric&lt;/strong&gt;: &lt;em&gt;&amp;quot;Low-Latency Kubernetes Scheduling for Heterogeneous ML Clusters&amp;quot;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="additional-tips-for-computer-systems-context"&gt;
&lt;h2&gt;Additional Tips for Computer Systems Context&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Reflect Systems Priorities&lt;/strong&gt;: Use terms like &amp;quot;optimizing,&amp;quot; &amp;quot;efficient,&amp;quot; or &amp;quot;scalable&amp;quot; to align with systems research goals (e.g., performance, scalability, resource efficiency).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reference the Platform&lt;/strong&gt;: Explicitly mentioning &amp;quot;Kubernetes&amp;quot; ensures relevance to cloud orchestration research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Highlight Application&lt;/strong&gt;: Including &amp;quot;machine learning workloads&amp;quot; ties to the growing importance of ML in systems research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Check Venue Fit&lt;/strong&gt;: For example, NSDI prefers titles emphasizing systems and networking, while ASPLOS may favor hardware-software integration (e.g., mentioning CPU/GPU/TPU).&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="acknowledgement"&gt;
&lt;h3&gt;Acknowledgement&lt;/h3&gt;
&lt;p&gt;This article was made with the help of Grok (accessed 2025-07-24)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Research Proposal"></category></entry><entry><title>Research Proposal Part 4: Writing the Review of Releated Literature</title><link href="https://srg-ics-uplb.github.io/blog/research-proposal-part-4-writing-the-review-of-releated-literature.html" rel="alternate"></link><published>2025-07-24T00:00:00+08:00</published><updated>2025-07-24T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2025-07-24:/blog/research-proposal-part-4-writing-the-review-of-releated-literature.html</id><summary type="html">&lt;p class="first last"&gt;The purpose of the review of related literature is to position your research, highlight the gap, demonstrate expertise, and provide context to your research.&lt;/p&gt;
</summary><content type="html">&lt;div class="section" id="purpose-of-the-review-of-related-literature-section"&gt;
&lt;h2&gt;Purpose of the Review of Related Literature Section&lt;/h2&gt;
&lt;p&gt;The review of related literature section serves to:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Position your research&lt;/strong&gt;: Show how your work builds on or differs from existing studies.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Highlight the gap&lt;/strong&gt;: Clearly articulate how existing solutions fall short, justifying your proposed research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Demonstrate expertise&lt;/strong&gt;: Prove your familiarity with the state-of-the-art in Computer Systems, particularly in Kubernetes, scheduling, and ML workloads for our running example.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Provide context&lt;/strong&gt;: For our running example, help readers understand the landscape of scheduling in heterogeneous systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="guidelines-for-writing-the-review"&gt;
&lt;h2&gt;Guidelines for Writing the Review&lt;/h2&gt;
&lt;p&gt;Specifics are for our running example.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;strong&gt;Organize by Themes or Categories&lt;/strong&gt;: Group related work into logical categories (e.g., general Kubernetes scheduling, heterogeneous systems, ML workload optimization) to make the review structured and easy to follow.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Focus on Relevance&lt;/strong&gt;: Prioritize papers directly related to Kubernetes scheduling, heterogeneous hardware, and ML workloads. Include seminal works and recent advancements (within the last 3-5 years, i.e., 2020-2025).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Critically Analyze&lt;/strong&gt;: For each work, summarize its contributions, strengths, and limitations, &lt;em&gt;explicitly linking limitations to your research gap&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use Authoritative Sources&lt;/strong&gt;: Cite top-tier conference and journal papers (e.g., OSDI, SOSP, NSDI, EuroSys, ASPLOS) and relevant industry whitepapers or open-source documentation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Be Concise and Targeted&lt;/strong&gt;: Aim for 1-2 paragraphs per category, focusing on key works (6-10 papers total) to avoid overwhelming the reader.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Highlight Your Contribution&lt;/strong&gt;: Conclude by summarizing how your work addresses the gaps identified in the literature.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use Clear Citations&lt;/strong&gt;: Follow a consistent citation style (e.g., IEEE, ACM) and include DOIs or URLs for accessibility.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="practical-steps-for-writing"&gt;
&lt;h2&gt;Practical Steps for Writing&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;strong&gt;Gather Sources&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;Search IEEE Xplore, ACM Digital Library, and arXiv for papers on Kubernetes scheduling, heterogeneous systems, and ML workloads (2020-2025).&lt;/li&gt;
&lt;li&gt;Check Kubernetes GitHub issues and documentation for practical insights.&lt;/li&gt;
&lt;li&gt;Monitor X for recent discussions (e.g., #Kubernetes, #MLSystems) to identify preprints or community critiques.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Organize and Summarize&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;Create a table or spreadsheet to track papers, their contributions, and limitations.&lt;/li&gt;
&lt;li&gt;Group papers into the three categories above (or adjust based on findings).&lt;/li&gt;
&lt;li&gt;Summarize each paper in 2-3 sentences, focusing on relevance to your gap.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Draft Critically&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;For each category, write a paragraph summarizing 2-3 key works, emphasizing their limitations.&lt;/li&gt;
&lt;li&gt;Use transitions to connect categories (e.g., &amp;quot;While Kubernetes schedulers address general workloads, they fall short in heterogeneous settings…&amp;quot;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Synthesize and Conclude&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;Write a final paragraph that ties the limitations to your research gap and briefly previews your solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Revise for Clarity&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;Ensure technical terms (e.g., pod, accelerator) are defined or clear from context.&lt;/li&gt;
&lt;li&gt;Verify citations are complete and follow the required style (e.g., [Author, Conference Year]).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="review-of-related-literature-example"&gt;
&lt;h2&gt;Review of Related Literature Example&lt;/h2&gt;
&lt;p&gt;For our running example, the review can be structured into three main subsections, each addressing a relevant aspect of the research gap, followed by a synthesis that ties the discussion to your proposed work. Shown below is a possible structure for the RRL.&lt;/p&gt;
&lt;div class="section" id="kubernetes-scheduling-frameworks"&gt;
&lt;h3&gt;&lt;em&gt;1. Kubernetes Scheduling Frameworks&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Objective&lt;/strong&gt;: Review existing Kubernetes scheduling mechanisms and their limitations for heterogeneous ML workloads.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;Example Discussion&lt;/strong&gt;:&lt;/dt&gt;
&lt;dd&gt;&lt;em&gt;Kubernetes, a widely adopted container orchestration platform, uses a default scheduler that employs a two-phase approach: filtering and scoring [Kubernetes Documentation, 2025]. The default scheduler prioritizes general-purpose metrics like CPU and memory availability but does not account for specialized hardware (e.g., GPUs, TPUs) or ML workload characteristics (e.g., data parallelism). Recent work, such as Firmament [Gog et al., SOSP 2019], integrates flow-based scheduling into Kubernetes, improving throughput for general workloads but lacking specific optimizations for heterogeneous accelerators. Similarly, Volcano [Volcano, 2024] supports batch scheduling for ML tasks but struggles with dynamic resource allocation in mixed CPU/GPU/TPU clusters, as noted in its GitHub issue tracker. These limitations highlight the need for a scheduler tailored to heterogeneous ML environments.&lt;/em&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="scheduling-for-heterogeneous-systems"&gt;
&lt;h3&gt;&lt;em&gt;2. Scheduling for Heterogeneous Systems&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Objective&lt;/strong&gt;: Analyze scheduling approaches in heterogeneous computing environments beyond Kubernetes.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;Example Discussion&lt;/strong&gt;:&lt;/dt&gt;
&lt;dd&gt;&lt;em&gt;Scheduling for heterogeneous systems has been explored in contexts like cloud computing and HPC. For instance, Tiresias [Gu et al., NSDI 2020] proposes a GPU cluster scheduler that optimizes for ML training jobs by predicting job duration and prioritizing short tasks. However, Tiresias assumes uniform GPU types and does not address TPU or mixed-accelerator scenarios. Another work, Themis [Mahajan et al., ASPLOS 2021], introduces fairness-aware scheduling for GPU clusters but incurs high overhead in multi-tenant settings with diverse hardware. These approaches, while effective for specific accelerators, do not generalize to Kubernetes clusters with mixed CPU/GPU/TPU nodes, leaving a gap in flexible, hardware-aware scheduling.&lt;/em&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="optimization-for-ml-workloads"&gt;
&lt;h3&gt;&lt;em&gt;3. Optimization for ML Workloads&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Objective&lt;/strong&gt;: Examine systems designed for ML workload optimization, focusing on their scheduling limitations.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;Example Discussion&lt;/strong&gt;:&lt;/dt&gt;
&lt;dd&gt;&lt;em&gt;ML workloads, such as deep learning training and inference, impose unique demands on system resources. Systems like Allox [Kaur et al., EuroSys 2023] optimize resource allocation for ML jobs in cloud environments by modeling workload dependencies but are not integrated with Kubernetes. Similarly, Google's Borg scheduler [Verma et al., EuroSys 2015] supports large-scale ML workloads but is proprietary and not optimized for open-source platforms like Kubernetes. Recent studies [Wang et al., OSDI 2024] highlight that ML workloads on heterogeneous clusters suffer from resource contention and suboptimal placement due to a lack of hardware-aware scheduling policies. This underscores the need for a Kubernetes-native solution tailored to ML workload demands.&lt;/em&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="synthesis-and-gap-identification"&gt;
&lt;h3&gt;&lt;em&gt;4. Synthesis and Gap Identification&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Objective&lt;/strong&gt;: Summarize the limitations of existing work and position your research as a solution.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;Example Discussion&lt;/strong&gt;:&lt;/dt&gt;
&lt;dd&gt;&lt;em&gt;Existing Kubernetes schedulers, such as the default scheduler and Volcano, are designed for general-purpose or batch workloads but lack fine-grained support for heterogeneous hardware and ML-specific requirements. While systems like Tiresias and Themis address GPU scheduling, they do not generalize to mixed CPU/GPU/TPU clusters or integrate with Kubernetes. Furthermore, ML workload optimizations, as seen in Allox, are not designed for containerized environments. Our work addresses these gaps by proposing a Kubernetes scheduler extension that optimizes pod placement for ML workloads on heterogeneous clusters, improving performance, resource utilization, and scalability.&lt;/em&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="tips-for-computer-systems-context"&gt;
&lt;h2&gt;Tips for Computer Systems Context&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Emphasize Systems Metrics&lt;/strong&gt;: Discuss how existing works measure performance (e.g., throughput, latency, resource utilization) and where they fall short for ML workloads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Address Practicality&lt;/strong&gt;: Highlight gaps in real-world applicability, especially for open-source platforms like Kubernetes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consider Scalability and Robustness&lt;/strong&gt;: Note limitations in handling large-scale or failure-prone clusters, as these are critical in systems research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stay Current&lt;/strong&gt;: Use recent papers (2020-2025) and check preprints on arXiv or discussions on X to ensure your review reflects the latest trends.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next post will focus on the &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-5-writing-the-title.html"&gt;Title&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="acknowledgement"&gt;
&lt;h2&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;This article was made with the help of Grok (accessed 2025-07-24)&lt;/p&gt;
&lt;/div&gt;
</content><category term="Research Proposal"></category></entry><entry><title>Research Proposal Part 3: Writing the Aim, Objectives, and Methods</title><link href="https://srg-ics-uplb.github.io/blog/research-proposal-part-3-writing-the-aim-objectives-and-methods.html" rel="alternate"></link><published>2025-07-23T00:00:00+08:00</published><updated>2025-07-23T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2025-07-23:/blog/research-proposal-part-3-writing-the-aim-objectives-and-methods.html</id><summary type="html">&lt;p class="first last"&gt;The Aims, Objectives, and Methods should be clearly articulated as this is what the researcher is set to achieve for the research.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;Once a research gap has been identified and Problem Statement has been drafted, the Aim, Objectives, and Methods can now be written. Below is a short discussion on how to write the Aim, Objectives, and Methods for a research proposal based on the example from &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-1-finding-and-identifying-research-gaps.html"&gt;Approach 5: Analyzing real-world systems and industry needs&lt;/a&gt;. The example identified a research gap in &lt;em&gt;developing a Kubernetes scheduler extension that optimizes for heterogeneous hardware in ML-heavy clusters&lt;/em&gt;, inspired by unresolved issues in the Kubernetes GitHub tracker about inefficient pod scheduling on mixed CPU/GPU/TPU nodes.&lt;/p&gt;
&lt;p&gt;When crafting a research proposal for this gap, the Aim, Objectives, and Methods sections should clearly articulate the purpose, specific goals, and approach to addressing the problem. These sections must be concise, focused, and aligned with the identified gap, ensuring the research is feasible and impactful in the context of Computer Systems.&lt;/p&gt;
&lt;div class="section" id="aim-aka-general-objective"&gt;
&lt;h2&gt;1. Aim (aka General Objective)&lt;/h2&gt;
&lt;p&gt;The Aim is a single, high-level statement that captures the overall purpose of the research. It should directly address the research gap and highlight the intended contribution to the field.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Guidelines&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Be specific about the problem (inefficient scheduling in Kubernetes for heterogeneous ML clusters).&lt;/li&gt;
&lt;li&gt;Emphasize the desired outcome (improved performance, resource utilization, or fairness).&lt;/li&gt;
&lt;li&gt;Keep it concise (1–2 sentences) and avoid technical jargon to ensure clarity.&lt;/li&gt;
&lt;li&gt;Align with the gap’s real-world relevance (e.g., supporting machine learning workloads).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example Aim&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The aim of this research is to develop a Kubernetes scheduler extension that optimizes pod placement for machine learning workloads on heterogeneous clusters, enhancing performance and resource utilization.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="specific-objectives"&gt;
&lt;h2&gt;2. (Specific) Objectives&lt;/h2&gt;
&lt;p&gt;The Objectives break down the aim into specific, measurable, and achievable goals. They should outline the key steps or outcomes needed to address the research gap.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Guidelines&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Use actionable verbs (e.g., design, evaluate, implement) to describe what will be achieved.&lt;/li&gt;
&lt;li&gt;Ensure objectives are SMART (Specific, Measurable, Achievable, Relevant, Time-bound).&lt;/li&gt;
&lt;li&gt;Cover both technical (e.g., algorithm design) and evaluative (e.g., performance analysis) aspects.&lt;/li&gt;
&lt;li&gt;Typically, include 3–5 objectives to keep the scope manageable.&lt;/li&gt;
&lt;li&gt;Reflect the systems-specific context (e.g., handling GPUs/TPUs, improving ML workload efficiency).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example Objectives&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Specifically, this study intends to:&lt;/em&gt;&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;em&gt;design a scheduling algorithm that accounts for heterogeneous hardware (CPU, GPU, TPU) characteristics in Kubernetes clusters;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;implement the proposed scheduler extension as a pluggable module in the Kubernetes framework;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;evaluate the scheduler’s performance in terms of throughput, latency, and resource utilization for ML workloads compared to the default Kubernetes scheduler; and&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;assess the scheduler’s scalability and robustness under diverse ML workloads and cluster configurations.&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="methods"&gt;
&lt;h2&gt;3. Methods&lt;/h2&gt;
&lt;p&gt;The Methods section describes the technical approach to achieving the objectives. It should provide a clear, logical plan for designing, implementing, and evaluating the solution, tailored to the Computer Systems domain.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Guidelines&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Outline the key steps: algorithm design, implementation, experimentation, and evaluation.&lt;/li&gt;
&lt;li&gt;Specify tools, platforms, or frameworks (e.g., Kubernetes, ML benchmarks like MLPerf).&lt;/li&gt;
&lt;li&gt;Describe the experimental setup, including hardware (e.g., heterogeneous clusters) and metrics (e.g., throughput, latency).&lt;/li&gt;
&lt;li&gt;Address how the methods tackle the gap (e.g., optimizing for heterogeneous hardware).&lt;/li&gt;
&lt;li&gt;Ensure feasibility by leveraging existing tools and datasets where possible.&lt;/li&gt;
&lt;li&gt;Include validation or comparison against baselines (e.g., default Kubernetes scheduler).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example Methods&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;To address the identified gap, the research will proceed as follows:&lt;/em&gt;&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;em&gt;Algorithm Design: Develop a scheduling algorithm that incorporates hardware-specific metrics (e.g., GPU memory bandwidth, TPU compute capacity) and ML workload requirements (e.g., data parallelism, model size). The algorithm will use a weighted scoring model to prioritize pod placement based on resource compatibility and workload demands.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Implementation: Implement the scheduler as a custom Kubernetes scheduler extension using Go, integrated with the Kubernetes API. The extension will leverage kube-scheduler’s pluggable architecture to ensure compatibility with existing clusters.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Experimental Setup: Deploy a testbed cluster with mixed CPU (Intel Xeon), GPU (NVIDIA A100), and TPU (Google Cloud TPU v4) nodes using a cloud provider like Google Kubernetes Engine (GKE). Use ML workloads from MLPerf (e.g., ResNet, BERT) to simulate real-world scenarios.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Evaluation: Compare the proposed scheduler against the default Kubernetes scheduler and state-of-the-art alternatives (e.g., Volcano). Measure key metrics: (a) throughput (tasks completed per second), (b) latency (task completion time), (c) resource utilization (CPU/GPU/TPU usage), and (d) scheduling overhead. Conduct experiments under varying cluster sizes (4–16 nodes) and workload intensities.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Validation: Analyze results to confirm improvements in performance and scalability, and validate robustness by introducing synthetic failures (e.g., node crashes) to test fault tolerance.&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="discussion"&gt;
&lt;h3&gt;Discussion&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Aim&lt;/strong&gt;: The example aim is concise and directly targets the gap by focusing on optimizing Kubernetes scheduling for heterogeneous ML clusters. It emphasizes practical impact (performance, resource utilization), which is critical for industry adoption.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Objectives&lt;/strong&gt;: The objectives break the aim into actionable steps, covering design, implementation, and evaluation. They are specific (e.g., handling CPU/GPU/TPU) and measurable (e.g., throughput, latency), ensuring the research is focused and achievable within a typical systems project timeline.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Methods&lt;/strong&gt;: The methods provide a clear roadmap, leveraging existing tools (Kubernetes, MLPerf, GKE) to ensure feasibility. The experimental setup reflects real-world ML cluster scenarios, and the comparison with baselines (default scheduler, Volcano) strengthens the evaluation. The inclusion of fault tolerance testing aligns with systems research priorities like robustness.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next post will focus on the &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-4-writing-the-review-of-releated-literature.html"&gt;Review of Related Literature&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="acknowledgement"&gt;
&lt;h3&gt;Acknowledgement&lt;/h3&gt;
&lt;p&gt;This article was made with the help of Grok (accessed 2025-07-23)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Research Proposal"></category></entry><entry><title>Research Proposal Part 2: Writing the Problem Statement</title><link href="https://srg-ics-uplb.github.io/blog/research-proposal-part-2-writing-the-problem-statement.html" rel="alternate"></link><published>2025-07-22T00:00:00+08:00</published><updated>2025-07-22T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2025-07-22:/blog/research-proposal-part-2-writing-the-problem-statement.html</id><summary type="html">&lt;p&gt;Once a research gap has been identified, a Problem Statement can be created. Below is a short discussion on how to write the Problem Statement for a research proposal based on the example from &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-1-finding-and-identifying-research-gaps.html"&gt;Approach        5: Analyzing real-world systems and industry needs&lt;/a&gt;. The example identified a research gap in &lt;em&gt;developing …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Once a research gap has been identified, a Problem Statement can be created. Below is a short discussion on how to write the Problem Statement for a research proposal based on the example from &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-1-finding-and-identifying-research-gaps.html"&gt;Approach        5: Analyzing real-world systems and industry needs&lt;/a&gt;. The example identified a research gap in &lt;em&gt;developing a Kubernetes scheduler extension that optimizes for heterogeneous hardware in ML-hea       vy clusters&lt;/em&gt;, inspired by unresolved issues in the Kubernetes GitHub tracker about inefficient pod scheduling on mixed CPU/GPU/TPU nodes.&lt;/p&gt;
&lt;div class="section" id="define-the-problem-clearly"&gt;
&lt;h2&gt;1. Define the Problem Clearly&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;What is the issue?&lt;/strong&gt; Specify the core limitation or deficiency in existing systems (e.g., inefficient scheduling for heterogeneous ML clusters).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Context&lt;/strong&gt;: Provide enough background to make the problem understandable to both experts and non-experts in Computer Systems.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scope&lt;/strong&gt;: Narrow the focus to the specific domain (Kubernetes, heterogeneous clusters, ML workloads) to avoid being overly broad.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="highlight-the-impact"&gt;
&lt;h2&gt;2. Highlight the Impact&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Why is it significant?&lt;/strong&gt; Explain the consequences of the gap (e.g., poor performance, wasted resources, limited scalability).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Who is affected?&lt;/strong&gt; Identify stakeholders (e.g., cloud providers, ML practitioners, DevOps engineers).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Real-world relevance&lt;/strong&gt;: Connect to practical scenarios, such as deploying ML models in production environments.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="justify-the-need-for-a-solution"&gt;
&lt;h2&gt;3. Justify the Need for a Solution&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Why hasn't it been solved?&lt;/strong&gt; Reference limitations in existing work (e.g., lack of hardware-aware scheduling, poor integration with Kubernetes).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Why now?&lt;/strong&gt; Emphasize current trends (e.g., increasing adoption of heterogeneous accelerators, growing demand for ML in cloud environments).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Feasibility&lt;/strong&gt;: Suggest that the problem is tractable with current tools and expertise.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="frame-as-a-research-problem"&gt;
&lt;h2&gt;4. Frame as a Research Problem&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Structure&lt;/strong&gt;: Combine the issue, its impact, and the need for a solution into a concise statement (1-2 sentences).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tone&lt;/strong&gt;: Use precise, formal language suitable for a research proposal, avoiding vague terms like &amp;quot;better&amp;quot; or &amp;quot;improved&amp;quot; without context.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alignment&lt;/strong&gt;: Ensure the statement directly ties to the research gap and sets up the aim and objectives of your study.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="validate-the-statement"&gt;
&lt;h2&gt;5. Validate the Statement&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Specificity&lt;/strong&gt;: Does it clearly address the gap (heterogeneous ML scheduling in Kubernetes)?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Relevance&lt;/strong&gt;: Does it connect to current challenges in Computer Systems?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Actionability&lt;/strong&gt;: Does it suggest a research direction (e.g., designing a new scheduler)?&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="example-problem-statement"&gt;
&lt;h3&gt;Example Problem Statement&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&amp;quot;The default Kubernetes scheduler and existing alternatives, such as Volcano, lack fine-grained support for optimizing pod placement on heterogeneous clusters comprising CPUs, GPUs, and TPUs, resulting in suboptimal performance, resource underutilization, and limited scalability for machine learning workloads. As the adoption of heterogeneous accelerators and ML-driven applications grows in cloud environments, there is an urgent need for a Kubernetes-native scheduling solution that effectively leverages diverse hardware to meet the performance and efficiency demands of modern ML workflows.&amp;quot;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="discussion-of-the-example"&gt;
&lt;h3&gt;Discussion of the Example&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Clarity&lt;/strong&gt;: The problem statement specifies the issue (lack of fine-grained scheduling support for heterogeneous clusters) and the context (Kubernetes, ML workloads).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Impact&lt;/strong&gt;: It highlights consequences (suboptimal performance, resource underutilization, limited scalability) and stakeholders (cloud providers, ML practitioners).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Need&lt;/strong&gt;: It underscores the urgency due to trends (growing use of heterogeneous accelerators, ML adoption) and implies the gap is unaddressed by referencing limitations in existing schedulers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alignment with Gap&lt;/strong&gt;: The statement directly reflects the research gap, focusing on the need for a Kubernetes-native, hardware-aware scheduler for ML workloads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Research Framing&lt;/strong&gt;: It sets up the proposed research (a new scheduler) without prescribing the solution, leaving room for the &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-3-writing-the-aim-objectives-and-methods.html"&gt;aim and objectives&lt;/a&gt; to elaborate.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="tips-for-computer-systems-context"&gt;
&lt;h3&gt;Tips for Computer Systems Context&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Emphasize Systems Metrics&lt;/strong&gt;: Include terms like &amp;quot;performance,&amp;quot; &amp;quot;resource utilization,&amp;quot; or &amp;quot;scalability&amp;quot; to align with systems research priorities.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ground in Practicality&lt;/strong&gt;: Reference real-world platforms (e.g., Kubernetes) and workloads (e.g., ML) to make the problem relevant to industry and academia.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Leverage Trends&lt;/strong&gt;: Tie the problem to current technological shifts, such as the rise of TPUs or edge computing, to justify timeliness.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Be Concise&lt;/strong&gt;: Aim for 1-2 sentences to maintain focus, as seen in the example.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next post will focus on the &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-3-writing-the-aim-objectives-and-methods.html"&gt;Aims, Objectives, and Methods&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="acknowledgement"&gt;
&lt;h3&gt;Acknowledgement&lt;/h3&gt;
&lt;p&gt;This article was made with the help of Grok (accessed 2025-07-22)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Research Proposal"></category></entry><entry><title>Research Proposal Part 1: Finding and Identifying Research Gaps</title><link href="https://srg-ics-uplb.github.io/blog/research-proposal-part-1-finding-and-identifying-research-gaps.html" rel="alternate"></link><published>2025-07-21T00:00:00+08:00</published><updated>2025-07-24T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2025-07-21:/blog/research-proposal-part-1-finding-and-identifying-research-gaps.html</id><summary type="html">&lt;p class="first last"&gt;A series of posts to help students come up with a research proposal for their CMSC 190/200/300 or for publication in conferences and journals. I used AI tools to create these posts, Grok in particular. Although this is tailored for systems research, the ideas apply to other fields also.&lt;/p&gt;
</summary><content type="html">&lt;img alt="" class="align-center" src="./images/jach/008_gaps.png" style="width: 50%;" /&gt;
&lt;p&gt;A series of posts to help students come up with a research proposal for their CMSC 190/200/300 or for publication in conferences and journals. I used AI tools to create these posts, Grok in particular.  Although this is tailored for systems research, the ideas apply to other fields also.&lt;/p&gt;
&lt;p&gt;A research endeavor usually starts by identifying research gaps. A research gap is 'something' (question, concept, approach)
within a research area that has not been answered or addressed yet and thus have limited discussion in the
literature. In this post, some approaches (with techniques and examples) to find and identify research gaps in computer systems research are presented.&lt;/p&gt;
&lt;div class="section" id="conduct-a-comprehensive-literature-review"&gt;
&lt;h2&gt;1. Conduct a Comprehensive Literature Review&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Understand the state-of-the-art and identify areas that are underexplored or unresolved.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Systematic Search&lt;/strong&gt;: Use academic databases like IEEE Xplore, ACM Digital Library, Springer, arXiv, and Google Scholar to search for recent papers, surveys, and reviews in your subfield (e.g., cloud computing, storage systems, or machine learning systems).&lt;ul&gt;
&lt;li&gt;Use specific keywords (e.g., “energy-efficient computing,” “scalable distributed systems”) and combine them with Boolean operators (AND, OR, NOT) to refine results.&lt;/li&gt;
&lt;li&gt;Filter for recent publications (last 3–5 years) to focus on current trends.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Read Survey Papers and Reviews&lt;/strong&gt;: Surveys often summarize open challenges and future directions explicitly. For example, look for “Open Problems” or “Future Work” sections in journals like &lt;em&gt;ACM Computing Surveys&lt;/em&gt; or &lt;em&gt;IEEE Transactions&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Analyze Highly Cited Papers&lt;/strong&gt;: Identify foundational papers and check their “Future Work” sections or limitations to uncover unresolved issues.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Track Emerging Topics&lt;/strong&gt;: Monitor proceedings of top conferences (e.g., OSDI, SOSP, ASPLOS, ISCA, USENIX ATC) to spot new trends or areas with limited follow-up work.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: While reviewing IEEE Xplore for papers on distributed storage systems, you find a 2024 survey in ACM Computing Surveys on “Next-Generation Storage Systems.” The survey highlights that current systems like Ceph and HDFS are optimized for large-scale cloud environments but lack efficient support for geo-distributed edge storage with intermittent connectivity. The “Future Work” section suggests exploring decentralized storage protocols for edge environments, but no follow-up papers address this. &lt;em&gt;Gap&lt;/em&gt;: Designing a distributed storage system tailored for edge devices with unreliable network conditions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Pay attention to performance bottlenecks, scalability limitations, or security vulnerabilities mentioned in system evaluations, as these often point to gaps.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="identify-limitations-in-existing-work"&gt;
&lt;h2&gt;2. Identify Limitations in Existing Work&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Pinpoint weaknesses or constraints in current systems or methodologies that your research can address.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Scrutinize Evaluation Sections&lt;/strong&gt;: Look at how systems are evaluated (e.g., benchmarks, workloads, or metrics). Are there scenarios where the system underperforms?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Examine Assumptions&lt;/strong&gt;: Many systems papers make simplifying assumptions (e.g., homogeneous hardware, idealized network conditions). Gaps often exist where these assumptions don’t hold.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Check Scalability and Applicability&lt;/strong&gt;: Investigate if current solutions scale to emerging technologies or fail under new constraints.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Look for Trade-offs&lt;/strong&gt;: Gaps may lie in optimizing trade-offs or mitigating their downsides.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: A 2023 OSDI paper on a new memory management system for cloud servers assumes homogeneous memory latency across NUMA nodes. Its evaluation shows performance degradation when applied to disaggregated memory systems (e.g., where memory is accessed over a network). &lt;em&gt;Gap&lt;/em&gt;: Developing memory management techniques that optimize for disaggregated memory architectures with variable latency.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Focus on practical deployment gaps—e.g., systems that work well in labs but not in real-world environments.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="engage-with-the-research-community"&gt;
&lt;h2&gt;3. Engage with the Research Community&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Leverage discussions and feedback from experts to uncover less-visible gaps.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Attend conferences and workshops (e.g., NSDI, EuroSys, HotOS).&lt;/li&gt;
&lt;li&gt;Join mailing lists and forums (e.g., ACM SIGOPS or SIGARCH).&lt;/li&gt;
&lt;li&gt;Collaborate and network with peers or practitioners.&lt;/li&gt;
&lt;li&gt;Follow posts from researchers or organizations on platforms like X.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: At SOSP 2025, during a panel on “Systems for AI Workloads,” a researcher mentions that current GPU scheduling frameworks (e.g., NVIDIA’s MPS) struggle with dynamic multi-tenant AI workloads due to poor isolation and resource contention. No solutions are proposed in the discussion. &lt;em&gt;Gap&lt;/em&gt;: Creating a GPU scheduling framework that ensures strong isolation and fairness for multi-tenant AI inference in data centers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Collaborate with industry to find real-world deployment gaps.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="explore-interdisciplinary-and-emerging-areas"&gt;
&lt;h2&gt;4. Explore Interdisciplinary and Emerging Areas&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Identify gaps at the intersection of systems and other domains or new trends.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Analyze cross-disciplinary interactions (e.g., with ML, IoT, or crypto).&lt;/li&gt;
&lt;li&gt;Monitor emerging technologies (e.g., TPUs, serverless, disaggregated memory).&lt;/li&gt;
&lt;li&gt;Examine application domains (e.g., AR/VR, autonomous vehicles).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: While exploring the intersection of Computer Systems and quantum computing, you notice that existing operating systems lack support for scheduling hybrid classical-quantum workloads. Papers on quantum computing focus on algorithms but not on system-level integration with classical hardware. &lt;em&gt;Gap&lt;/em&gt;: Designing an operating system scheduler that optimizes resource allocation for hybrid quantum-classical computing environments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Gaps often arise when adapting systems to new use cases or hardware.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="analyze-real-world-systems-and-industry-needs"&gt;
&lt;h2&gt;5. Analyze Real-World Systems and Industry Needs&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Ground your research in real-world issues.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Study open-source systems and issues (e.g., Linux, Kubernetes).&lt;/li&gt;
&lt;li&gt;Read technical industry reports (e.g., Spanner, DynamoDB).&lt;/li&gt;
&lt;li&gt;Monitor news or posts about outages, bugs, or breaches.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: Analyzing the Kubernetes GitHub issue tracker, you find multiple unresolved issues about inefficient pod scheduling on heterogeneous clusters with mixed CPU/GPU/TPU nodes. Users report suboptimal performance for machine learning workloads. &lt;em&gt;Gap&lt;/em&gt;: Developing a Kubernetes scheduler extension that optimizes for heterogeneous hardware in ML-heavy clusters.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Look for practical challenges like energy, cost, and maintainability.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="leverage-quantitative-and-qualitative-analysis"&gt;
&lt;h2&gt;6. Leverage Quantitative and Qualitative Analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Use structured methods to find gaps.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Use SWOT or other gap analysis frameworks.&lt;/li&gt;
&lt;li&gt;Build taxonomies of existing work.&lt;/li&gt;
&lt;li&gt;Benchmark current systems.&lt;/li&gt;
&lt;li&gt;Survey experts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: You create a taxonomy of existing fault-tolerance mechanisms in distributed systems (e.g., checkpointing, replication, erasure coding). You notice that most mechanisms are designed for crash failures but not for Byzantine failures in large-scale systems. A benchmark you run on Apache Spark reveals high overhead when handling Byzantine faults. &lt;em&gt;Gap&lt;/em&gt;: Designing lightweight Byzantine fault-tolerant protocols for large-scale distributed data processing systems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Quantitative analysis of metrics (e.g., latency, energy) can highlight performance gaps.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="focus-on-future-work-and-open-questions"&gt;
&lt;h2&gt;7. Focus on “Future Work” and Open Questions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Mine existing research for explicitly stated gaps.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Collect “Future Work” sections across papers.&lt;/li&gt;
&lt;li&gt;Look for speculative or abandoned ideas.&lt;/li&gt;
&lt;li&gt;Find threads in older papers that remain unresolved.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: A 2024 ASPLOS paper on serverless computing platforms notes that current platforms (e.g., AWS Lambda) struggle with cold-start latency for latency-sensitive applications like real-time video processing. The “Future Work” section suggests exploring predictive pre-warming but lacks implementation details. &lt;em&gt;Gap&lt;/em&gt;: Developing a predictive pre-warming mechanism to reduce cold-start latency in serverless platforms for real-time applications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Common themes include scalability and portability issues.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="experiment-and-prototype"&gt;
&lt;h2&gt;8. Experiment and Prototype&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Use experimentation to uncover practical gaps.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Build proof-of-concepts.&lt;/li&gt;
&lt;li&gt;Stress-test existing systems.&lt;/li&gt;
&lt;li&gt;Simulate future scenarios.&lt;/li&gt;
&lt;li&gt;Reproduce prior work.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: You prototype a distributed file system based on a recent NSDI paper and test it under high-latency network conditions (e.g., simulating 5G edge networks). The system exhibits significant performance degradation due to its reliance on synchronous replication. &lt;em&gt;Gap&lt;/em&gt;: Designing an asynchronous replication protocol that maintains consistency in high-latency edge environments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Prototyping reveals practical limitations (e.g., complexity, compatibility).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="stay-updated-with-real-time-information"&gt;
&lt;h2&gt;9. Stay Updated with Real-Time Information&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Ensure your gap analysis is current.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Search X for discussions or trending research hashtags.&lt;/li&gt;
&lt;li&gt;Monitor arXiv or preprint platforms.&lt;/li&gt;
&lt;li&gt;Watch funding agency calls (e.g., NSF, DARPA).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: On X, a systems researcher (&amp;#64;SysProf2025) posts about a recent arXiv preprint on secure enclaves (e.g., Intel SGX, AMD SEV). The discussion highlights that enclaves are vulnerable to side-channel attacks in multi-tenant cloud environments, with no robust mitigation for dynamic workloads. &lt;em&gt;Gap&lt;/em&gt;: Developing a secure enclave framework that mitigates side-channel attacks in multi-tenant cloud settings.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Real-time debates can signal overhyped or unworkable approaches.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="reflect-on-your-own-expertise-and-interests"&gt;
&lt;h2&gt;10. Reflect on Your Own Expertise and Interests&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Match research gaps to your skills and interests.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Map your expertise and look for domain-specific gaps.&lt;/li&gt;
&lt;li&gt;Brainstorm new applications for familiar techniques.&lt;/li&gt;
&lt;li&gt;Revisit your own past work for extensions or limitations.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: As an expert in computer architecture, you revisit your prior work on cache coherence protocols for multi-core CPUs. You realize that existing protocols are not optimized for emerging chiplet-based architectures, where cores are physically disaggregated. &lt;em&gt;Gap&lt;/em&gt;: Designing a cache coherence protocol tailored for chiplet-based processors to improve performance and energy efficiency.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Your unique viewpoint can spot overlooked gaps.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="practical-steps-to-validate-a-research-gap"&gt;
&lt;h2&gt;Practical Steps to Validate a Research Gap&lt;/h2&gt;
&lt;p&gt;Once you identify a potential gap:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;strong&gt;Novelty Check&lt;/strong&gt;: Ensure no recent work has addressed it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Impact Assessment&lt;/strong&gt;: Evaluate real-world or academic importance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Feasibility Analysis&lt;/strong&gt;: Check tools, data, and time constraints.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Community Feedback&lt;/strong&gt;: Get input from peers and mentors.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The above tasks can be done with your adviser and mentors.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="final-tips"&gt;
&lt;h2&gt;Final Tips&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Document Your Process&lt;/strong&gt;: Maintain a gap-tracking notebook or database.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Iterate Continuously&lt;/strong&gt;: Revisit gaps as literature and tech evolve.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Balance Novelty and Feasibility&lt;/strong&gt;: Choose problems that are new &lt;em&gt;and&lt;/em&gt; solvable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next post will focus on the &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-2-writing-the-problem-statement.html"&gt;Problem Statement&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="acknowledgement"&gt;
&lt;h2&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;This article was made with the help of Grok (accessed 2025-07-21)&lt;/p&gt;
&lt;/div&gt;
</content><category term="Research Proposal"></category></entry><entry><title>Dependability in Edge Computing</title><link href="https://srg-ics-uplb.github.io/blog/dependability-in-edge-computing.html" rel="alternate"></link><published>2020-02-17T00:00:00+08:00</published><updated>2020-02-17T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2020-02-17:/blog/dependability-in-edge-computing.html</id><summary type="html">&lt;p&gt;This article [&lt;a class="reference internal" href="#bagchi2019"&gt;BAGCHI2019&lt;/a&gt;] addresses three challenges related to the dependability of edge computing namely:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;How should failures be handled?&lt;/li&gt;
&lt;li&gt;How should security and privacy issues be addressed?&lt;/li&gt;
&lt;li&gt;How should multi-tenancy be addressed in resource-constrained edge devices?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Edge computing attempts to improve the performance of software applications by placing computing resources …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This article [&lt;a class="reference internal" href="#bagchi2019"&gt;BAGCHI2019&lt;/a&gt;] addresses three challenges related to the dependability of edge computing namely:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;How should failures be handled?&lt;/li&gt;
&lt;li&gt;How should security and privacy issues be addressed?&lt;/li&gt;
&lt;li&gt;How should multi-tenancy be addressed in resource-constrained edge devices?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Edge computing attempts to improve the performance of software applications by placing computing resources closer to user devices and information sources. This has the effect of increasing the bandwidth and reducing latency. The word &amp;quot;edge&amp;quot; refers to the location of the computing resources in the network topology. In the case of the Internet, it is about two hops (routers) away from the user's device.&lt;/p&gt;
&lt;p&gt;For example, a smart toaster (the IoT device) with limited computing capabilities that needs to perform machine learning can use the edge server located in the datacenter of the ISP (a home router can also act as edge server). The traditional approach would be to offload the computation to Google servers over the cloud.&lt;/p&gt;
&lt;p&gt;The key idea is that if the user's device (local) cannot perform the required operation, it can offload the computation to a device near it (edge) instead of a server-class device (cloud) located across the globe.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;How should failures be handled?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Since edge computing is in its infancy, most design decisions are made on a small scale. However, the number of user devices connecting to the network continues to increase. In addition, IoT devices continue to generate large volumes of data.  This results in the clogging of the network with some requests being dropped.  Time-critical applications will fail since computations will be forwarded to the cloud.&lt;/p&gt;
&lt;p&gt;One way to solve this lack of failover options is to agree on peer-based failover, similar to what is being done in microgrids. To solve real-time requirements, edge devices can forward delay-tolerant computations to the cloud to lessen the workload on the edge devices. The scheduler can then prioritize time-critical applications.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;How should security and privacy issues be addressed?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Edge devices will most probably be cheap (compared to server-grade machines used in the cloud) and will be heterogeneous. This will require mechanisms that can guarantee privacy and security in edge devices with limited computing resources and with different configurations.&lt;/p&gt;
&lt;p&gt;In particular, edge devices are easy to access physically since they are near the vicinity of user devices. This makes them susceptible to physical tampering. Traditional security mechanisms like code signatures and PKI can still be used but with some performance degradation. Device management will require some form of key-based authentication to make sure that edge devices have not been modified after deployment. Finally, updates should be made regularly on edge devices to patch vulnerabilities.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;How should multi-tenancy be addressed in resource-constrained edge devices?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Edge devices should be able to support multiple tenants or applications in the same manner as the cloud. Issues such as billing and scheduling will need to be addressed also. All these should be done in resource-constrained devices.&lt;/p&gt;
&lt;p&gt;Two example applications in the context of the issues described above, a smart toaster and a smart door lock, were presented in the paper. These two applications have different requirements in terms of bandwidth and latency.&lt;/p&gt;
&lt;p&gt;My takeaway from this paper is that edge computing is very similar to cloud computing. One difference is that edge devices are resource-constrained compared to cloud servers. This makes it difficult to make these systems dependable. Management is also a challenge  as edge devices are heterogeneous and owned by different entities.&lt;/p&gt;
&lt;table class="docutils citation" frame="void" id="bagchi2019" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;[BAGCHI2019]&lt;/td&gt;&lt;td&gt;Saurabh Bagchi, Muhammad-Bilal Siddiqui, Paul Wood, and Heng Zhang. 2019. Dependability in edge computing. Commun. ACM 63, 1 (December 2019), 58–66. &lt;a class="reference external" href="https://doi.org/10.1145/3362068"&gt;DOI:https://doi.org/10.1145/3362068&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content><category term="Paper Review"></category></entry><entry><title>Fuzzing: Hack, Art, and Science</title><link href="https://srg-ics-uplb.github.io/blog/fuzzing-hack-art-and-science.html" rel="alternate"></link><published>2020-01-27T00:00:00+08:00</published><updated>2020-01-27T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2020-01-27:/blog/fuzzing-hack-art-and-science.html</id><summary type="html">&lt;p&gt;A program usually accepts input, performs operations on the input, and produces output.  Incorrect processing of input can lead to security vulnerabilities, such as buffer overflow. Depending on the input, the program may not perform the desired operation. An attacker can craft a specialized input that exploits the vulnerability to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A program usually accepts input, performs operations on the input, and produces output.  Incorrect processing of input can lead to security vulnerabilities, such as buffer overflow. Depending on the input, the program may not perform the desired operation. An attacker can craft a specialized input that exploits the vulnerability to take control of the machine running the vulnerable software.&lt;/p&gt;
&lt;p&gt;This paper [&lt;a class="reference internal" href="#godefroid2020"&gt;GODEFROID2020&lt;/a&gt;] gives an overview of fuzzing as a way to detect security vulnerabilities. Other approaches mentioned in the paper include the use of static program analyzers and manual code inspection. Fuzzing tests the behavior of a program against all, or a subset, of possible inputs to identify security vulnerabilities. It is an automated testing technique since there is a large set of possible inputs to a program.&lt;/p&gt;
&lt;p&gt;The paper discussed three fuzzing techniques. The first technique is called Blackbox Fuzzing. This technique uses well-formed inputs, mutates them, then use the mutated input to test the software.&lt;/p&gt;
&lt;p&gt;The second technique is Grammar-Based Fuzzing. This technique is useful if the input follows some form of structured formats such as JSON or XML. In this approach, the tester provides a grammar specifying the format. The fuzzer then generates input based on the provided grammar.&lt;/p&gt;
&lt;p&gt;The last technique is called Whitebox Fuzzing. This technique is more advanced since it uses dynamic symbolic execution. It gathers constraints on inputs as it executes a program from conditional branches. The constraints are negated and solved using a constraint solver. The solutions are then mapped to new inputs to pass through other execution paths in a program. SAGE is an example tool for Whitebox Fuzzing described in the paper.&lt;/p&gt;
&lt;p&gt;The conclusion is that the fuzzing technique to use depends on the type of program being tested. Programs that use binary input formats are best tested with Blackbox Fuzzing or Whitebox Fuzzing. Programs with more structured formats will benefit from Grammar-Based fuzzing.&lt;/p&gt;
&lt;table class="docutils citation" frame="void" id="godefroid2020" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;[GODEFROID2020]&lt;/td&gt;&lt;td&gt;Patrice Godefroid. 2020. Fuzzing: hack, art, and science. Commun. ACM 63, 2 (January 2020), 70–76. DOI:https://doi.org/10.1145/3363824&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content><category term="Paper Review"></category></entry><entry><title>Cloud Benchmarking for Maximising Performance of Scientific Applications</title><link href="https://srg-ics-uplb.github.io/blog/cloud-benchmarking-for-maximising-performance-of-scientific-applications.html" rel="alternate"></link><published>2019-04-29T00:00:00+08:00</published><updated>2019-04-29T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2019-04-29:/blog/cloud-benchmarking-for-maximising-performance-of-scientific-applications.html</id><summary type="html">&lt;p&gt;It is quite difficult for users to select VM configurations to optimize the
performance of their applications, especially if there are a lot of choices.
For example, if I want to run computational chemistry app, I need to make a decision
whether to use a VM with 1 VCPU and …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It is quite difficult for users to select VM configurations to optimize the
performance of their applications, especially if there are a lot of choices.
For example, if I want to run computational chemistry app, I need to make a decision
whether to use a VM with 1 VCPU and 2GB RAM or a VM with 2 VCPUs and 4GB RAM.&lt;/p&gt;
&lt;p&gt;Cloud providers run benchmarks to measure the performance of various VM configurations for applications.
However, these benchmarks are done independent of the application to be deployed. Most likely because
providers have no knowledge of what application will be deployed.&lt;/p&gt;
&lt;p&gt;This paper [&lt;a class="reference internal" href="#varghese2019"&gt;VARGHESE2019&lt;/a&gt;] addresses these issues by introducing an application-aware benchmarking
methodology. The main hypothesis presented in the paper is that by taking into account application
requirements in addition to benchmarking data, VMs can be ranked in order of performance and
cost-effectiveness to maximize performance. Although there are different kinds of applications
that can be run in the cloud, the paper focused on high-performance computing applications with
the goal of minimizing execution time to minimize costs. (Running applications in the cloud is
usually charged per hour.) The authors validated they results against real-world applications.
The following are the steps in the proposed methodology.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;Capture attributes of cloud VMs&lt;/li&gt;
&lt;li&gt;Group attributes of cloud VMs&lt;/li&gt;
&lt;li&gt;Benckmark cloud VMs&lt;/li&gt;
&lt;li&gt;Normalize attribute groups&lt;/li&gt;
&lt;li&gt;Provide weights to groups&lt;/li&gt;
&lt;li&gt;Rank cloud VMs&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Steps 5-6 are repeated for each deployment.&lt;/p&gt;
&lt;p&gt;In Step 2, the following are the identified attribute groups:
- memory and process
- local communication
- computation
- storage&lt;/p&gt;
&lt;p&gt;As for the benchmarking part, the researchers used bonnie++, lmbench, and sysbench.&lt;/p&gt;
&lt;p&gt;It is worth noting that this paper did not consider inter-VM communication. The
local communication is between the cores in the VM only. Perhaps a future work will
be to consider inter-VM communication in the methodology.&lt;/p&gt;
&lt;table class="docutils citation" frame="void" id="varghese2019" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;[VARGHESE2019]&lt;/td&gt;&lt;td&gt;Varghese, B., Akgun, O., Miguel, I., Thai, L., &amp;amp; Barker, A. (2019). Cloud Benchmarking for Maximising Performance of Scientific Applications. IEEE Transactions on Cloud Computing, 7(1), 170–182.&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content><category term="Paper Review"></category></entry><entry><title>Lock–Unlock: Is That All? A Pragmatic Analysis of Locking in Software Systems</title><link href="https://srg-ics-uplb.github.io/blog/lock-unlock-is-that-all-a-pragmatic-analysis-of-locking-in-software-systems.html" rel="alternate"></link><published>2019-04-14T00:00:00+08:00</published><updated>2019-04-14T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2019-04-14:/blog/lock-unlock-is-that-all-a-pragmatic-analysis-of-locking-in-software-systems.html</id><summary type="html">&lt;p&gt;Most processors nowadays are multi-core processors to take advantage of parallel processing.
Associated with parallel processing is the synchronization problem wherein locks are extensively
used. This paper &lt;a class="citation-reference" href="#guerraoui2019" id="citation-reference-1"&gt;[GUERRAOUI2019]&lt;/a&gt; argues that despite the large amount of available choices for
lock algorithms, developers do not have a comprehensive guide to select an …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Most processors nowadays are multi-core processors to take advantage of parallel processing.
Associated with parallel processing is the synchronization problem wherein locks are extensively
used. This paper &lt;a class="citation-reference" href="#guerraoui2019" id="citation-reference-1"&gt;[GUERRAOUI2019]&lt;/a&gt; argues that despite the large amount of available choices for
lock algorithms, developers do not have a comprehensive guide to select an algorithm. The paper also
asserts that most research on lock algorithms are limited to mutex locks and rarely consider other
techniques like trylocks and condition variables. In addition, most evaluation of lock algorithms
use workload that are specific to the design of the lock. Lastly, evaluation is focused only on throughput
neglecting energy efficiency and tail latency.&lt;/p&gt;
&lt;p&gt;The main contribution of this paper is a broad performance study of lock algorithms. Specifically,
28 state-of-the-art algorithms were studied and applied to 40 applications. The experiments where
conducted of 4 different multi-core machines. As mentioned, this study considered energy efficiency and
tail latency, in addition to throughtput, as metrics in the evaluation. In the paper, the authors
claimed that it is really difficult to choose a well-performing lock for an application because of
several factors: workload, hardware, degree of parallelism, number of locks, how they are used, interaction
between the application and the CPU scheduler, and metric. The authors also developed a library called LiTL
used for testing the applications.&lt;/p&gt;
&lt;p&gt;The authors have the following observations as a result of their study&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Trylocks and condition variables should also be considered&lt;/li&gt;
&lt;li&gt;Memory footprint of lock algorithms affect performance&lt;/li&gt;
&lt;li&gt;Interaction between locks and scheduling affects performance&lt;/li&gt;
&lt;li&gt;Lock tail latency may not affect application tail latency&lt;/li&gt;
&lt;li&gt;No single lock is systematically the best&lt;/li&gt;
&lt;li&gt;Choosing the best lock is difficult&lt;/li&gt;
&lt;li&gt;Energy efficiency and throughput go hand-in-hand in lock algorithms&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;The figure below is a guide for developers in selecting the appropriate lock considering
the findings of the the study.&lt;/p&gt;
&lt;img alt="" src="./images/jach/locks.png" style="width: 40%;" /&gt;
&lt;table class="docutils citation" frame="void" id="guerraoui2019" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#citation-reference-1"&gt;[GUERRAOUI2019]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;Guerraoui, R., Guiroux, H., Lachaize, R., Quéma, V., &amp;amp; Trigonakis, V. (2019). Lock–Unlock: Is That All? A Pragmatic Analysis of Locking in Software Systems. ACM Transactions on Computer Systems, 36(1), 1–149. &lt;a class="reference external" href="https://doi.org/10.1145/3301501"&gt;https://doi.org/10.1145/3301501&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content><category term="Paper Review"></category></entry><entry><title>Contiki - a Lightweight and Flexible Operating System for Tiny Networked Sensors</title><link href="https://srg-ics-uplb.github.io/blog/contiki-a-lightweight-and-flexible-operating-system-for-tiny-networked-sensors.html" rel="alternate"></link><published>2019-03-23T00:00:00+08:00</published><updated>2019-03-23T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2019-03-23:/blog/contiki-a-lightweight-and-flexible-operating-system-for-tiny-networked-sensors.html</id><summary type="html">&lt;p&gt;This paper &lt;a class="citation-reference" href="#dunkels2005" id="citation-reference-1"&gt;[DUNKELS2005]&lt;/a&gt; describes the design and implementation of Contiki. The paper describes the characteristics of sensor
networks and its special requirements. These special requirements were considered in Contiki's design. For example,
nodes in sensor networks are tiny and limited in processing power and memory. Thus, Contiki should be able …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This paper &lt;a class="citation-reference" href="#dunkels2005" id="citation-reference-1"&gt;[DUNKELS2005]&lt;/a&gt; describes the design and implementation of Contiki. The paper describes the characteristics of sensor
networks and its special requirements. These special requirements were considered in Contiki's design. For example,
nodes in sensor networks are tiny and limited in processing power and memory. Thus, Contiki should be able to
run on these devices. Contiki is an event-driven operating system which means that it responds when an event happens.
The main components of Contiki are the kernel, libraries, program loader, and a set of processes.&lt;/p&gt;
&lt;table class="docutils citation" frame="void" id="dunkels2005" rules="none"&gt;
&lt;colgroup&gt;&lt;col class="label" /&gt;&lt;col /&gt;&lt;/colgroup&gt;
&lt;tbody valign="top"&gt;
&lt;tr&gt;&lt;td class="label"&gt;&lt;a class="fn-backref" href="#citation-reference-1"&gt;[DUNKELS2005]&lt;/a&gt;&lt;/td&gt;&lt;td&gt;&lt;ol class="first last upperalpha simple"&gt;
&lt;li&gt;Dunkels, B. Gronvall, and T. Voigt, “Contiki - a lightweight and flexible operating system for tiny networked sensors,” in 29th Annual IEEE International Conference on Local Computer Networks, 2004, pp. 455–462.&lt;/li&gt;
&lt;/ol&gt;
&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
</content><category term="Paper Review"></category></entry><entry><title>How to contribute to this blog (Short Method)</title><link href="https://srg-ics-uplb.github.io/blog/how-to-contribute-to-this-blog-short-method.html" rel="alternate"></link><published>2019-02-02T00:00:00+08:00</published><updated>2019-03-06T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2019-02-02:/blog/how-to-contribute-to-this-blog-short-method.html</id><summary type="html">&lt;p&gt;This method is easier because the editing will be done in
github itself via the web browser.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Fork the original repository&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/srg-ics-uplb/blog"&gt;SRG Blog Repository&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is accomplished in github and you must be logged in. You should have
the repository under your account after the fork. The succeeding steps …&lt;/p&gt;</summary><content type="html">&lt;p&gt;This method is easier because the editing will be done in
github itself via the web browser.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Fork the original repository&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/srg-ics-uplb/blog"&gt;SRG Blog Repository&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is accomplished in github and you must be logged in. You should have
the repository under your account after the fork. The succeeding steps will be done on this forked repo.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Create your entries&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If this is your first entry, you must create a folder for your articles.&lt;/p&gt;
&lt;p&gt;Navigate to  &lt;tt class="docutils literal"&gt;&amp;quot;contents/articles&amp;quot;&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Click the &lt;tt class="docutils literal"&gt;&amp;quot;Create new file button&amp;quot;&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Specify the file name of the first entry, say &lt;tt class="docutils literal"&gt;&amp;quot;clinton/clinton_001.rst&amp;quot;&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;You can begin writing your article. Save.&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://docs.getpelican.com/en/3.6.3/content.html"&gt;Adding content&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/ralsina/rst-cheatsheet/blob/master/rst-cheatsheet.rst"&gt;More on RST Syntax&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For your succeeding articles, you can go directly to your own folder and
create the file there.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. Using images&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Navigate to  &lt;tt class="docutils literal"&gt;&amp;quot;contents/images&amp;quot;&lt;/tt&gt;.&lt;/p&gt;
&lt;p&gt;Upload your image, say &amp;quot;code.png&amp;quot;.&lt;/p&gt;
&lt;p&gt;To use your image in the article:&lt;/p&gt;
&lt;pre class="code html literal-block"&gt;
.. image:: ./images/code.png
&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;3. Make a pull request&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If your article is ready to be published, make a pull request.&lt;/p&gt;
</content><category term="How-To"></category></entry><entry><title>How to contribute to this blog (Long Method)</title><link href="https://srg-ics-uplb.github.io/blog/how-to-contribute-to-this-blog-long-method.html" rel="alternate"></link><published>2019-02-01T00:00:00+08:00</published><updated>2019-03-05T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2019-02-01:/blog/how-to-contribute-to-this-blog-long-method.html</id><summary type="html">&lt;p&gt;Contributions are encouraged from SRG members.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Set up the development environment&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;virtualenv&lt;span class="w"&gt; &lt;/span&gt;pelican-blog-venv
$&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;pelican-blog-venv/bin/activate
$&lt;span class="w"&gt; &lt;/span&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;pelican&lt;span class="w"&gt; &lt;/span&gt;markdown&lt;span class="w"&gt; &lt;/span&gt;ghp-import
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2. Fork the original repository&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/srg-ics-uplb/blog"&gt;SRG Blog Repository&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is accomplished in github and you must be logged in. You should have
the repository under your account …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Contributions are encouraged from SRG members.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Set up the development environment&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;virtualenv&lt;span class="w"&gt; &lt;/span&gt;pelican-blog-venv
$&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="nb"&gt;source&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;pelican-blog-venv/bin/activate
$&lt;span class="w"&gt; &lt;/span&gt;pip&lt;span class="w"&gt; &lt;/span&gt;install&lt;span class="w"&gt; &lt;/span&gt;pelican&lt;span class="w"&gt; &lt;/span&gt;markdown&lt;span class="w"&gt; &lt;/span&gt;ghp-import
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;2. Fork the original repository&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://github.com/srg-ics-uplb/blog"&gt;SRG Blog Repository&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is accomplished in github and you must be logged in. You should have
the repository under your account after the fork.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. Clone the repository from your account&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;clone&lt;span class="w"&gt; &lt;/span&gt;https://github.com/&amp;lt;YOUR_USERNAME&amp;gt;/blog.git
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;3. Configure a remote for your fork&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;remote&lt;span class="w"&gt; &lt;/span&gt;-v
$&lt;span class="w"&gt; &lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;remote&lt;span class="w"&gt; &lt;/span&gt;add&lt;span class="w"&gt; &lt;/span&gt;upstream&lt;span class="w"&gt; &lt;/span&gt;https://github.com/srg-ics-uplb/blog.git
$&lt;span class="w"&gt; &lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;remote&lt;span class="w"&gt; &lt;/span&gt;-v
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a class="reference external" href="https://help.github.com/en/articles/configuring-a-remote-for-a-fork"&gt;Help: Create a remote&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. Sync your fork with the upstream&lt;/strong&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;fetch&lt;span class="w"&gt; &lt;/span&gt;upstream
$&lt;span class="w"&gt; &lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;checkout&lt;span class="w"&gt; &lt;/span&gt;master
$&lt;span class="w"&gt; &lt;/span&gt;git&lt;span class="w"&gt; &lt;/span&gt;merge&lt;span class="w"&gt; &lt;/span&gt;upstream/master
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;a class="reference external" href="https://help.github.com/en/articles/syncing-a-fork"&gt;Help: Sync from upstream&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;5. Create your blog entry&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;At this point you are ready to write your entries. Create your own directory inside
content. You're going to place all your entries in this directory.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$&lt;span class="w"&gt; &lt;/span&gt;mkdir&lt;span class="w"&gt; &lt;/span&gt;-p&lt;span class="w"&gt; &lt;/span&gt;content/articles/&amp;lt;YOUR_NICKNAME&amp;gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For example, the source for this entry is &lt;a class="reference external" href="https://raw.githubusercontent.com/srg-ics-uplb/blog/master/content/articles/jach/jach_001.rst"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If your entry has images, place them in the images directory,&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Additional Resources&lt;/strong&gt;&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://docs.getpelican.com/en/3.6.3/content.html"&gt;Adding content&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/ralsina/rst-cheatsheet/blob/master/rst-cheatsheet.rst"&gt;More on RST Syntax&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;img alt="" src="./images/jach/srg.png" style="width: 60pt;" /&gt;
</content><category term="How-To"></category></entry></feed>