<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Lost Packets - Research Proposal</title><link href="https://srg-ics-uplb.github.io/blog/" rel="alternate"></link><link href="https://srg-ics-uplb.github.io/blog/feeds/research-proposal.atom.xml" rel="self"></link><id>https://srg-ics-uplb.github.io/blog/</id><updated>2025-07-24T23:00:00+08:00</updated><entry><title>Research Proposal Part 5: Writing the Title</title><link href="https://srg-ics-uplb.github.io/blog/research-proposal-part-5-writing-the-title.html" rel="alternate"></link><published>2025-07-24T23:00:00+08:00</published><updated>2025-07-24T23:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2025-07-24:/blog/research-proposal-part-5-writing-the-title.html</id><summary type="html">&lt;p class="first last"&gt;The title of a research proposal in Computer Systems should be clear, concise, and informative, conveying the key focus, contribution, and scope of the work. It should attract the attention of the target audience (e.g., systems researchers, industry practitioners) while adhering to academic standards.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;The title of a research proposal in Computer Systems should be clear, concise, and informative, conveying the key focus, contribution, and scope of the work. It should attract the attention of the target audience (e.g., systems researchers, industry practitioners) while adhering to academic standards. Below are the key guidelines for crafting an effective title for our running example:&lt;/p&gt;
&lt;div class="section" id="be-clear-and-specific"&gt;
&lt;h2&gt;1. Be Clear and Specific&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Objective&lt;/strong&gt;: Clearly describe the main focus of the research (e.g., Kubernetes scheduling, heterogeneous clusters, ML workloads).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Avoid Ambiguity&lt;/strong&gt;: Use precise terms to indicate the system, problem, or technology (e.g., &amp;quot;Kubernetes scheduler&amp;quot; instead of &amp;quot;orchestration system&amp;quot;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Highlight the Contribution&lt;/strong&gt;: Include the novel aspect (e.g., &amp;quot;extension,&amp;quot; &amp;quot;optimization&amp;quot;) to differentiate from existing work.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="incorporate-key-keywords"&gt;
&lt;h2&gt;2. Incorporate Key Keywords&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Include domain-specific terms to ensure the title is discoverable in academic databases (e.g., IEEE Xplore, ACM Digital Library) and aligns with Computer Systems terminology.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Examples&lt;/strong&gt;: Use terms like &amp;quot;scheduling,&amp;quot; &amp;quot;heterogeneous computing,&amp;quot; &amp;quot;machine learning workloads,&amp;quot; &amp;quot;Kubernetes,&amp;quot; &amp;quot;resource optimization.&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Balance&lt;/strong&gt;: Avoid overloading with jargon; aim for terms that are broadly understood in systems research.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="emphasize-novelty-and-impact"&gt;
&lt;h2&gt;3. Emphasize Novelty and Impact&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Highlight the Gap&lt;/strong&gt;: Suggest how the research addresses an unsolved problem (e.g., &amp;quot;optimized for heterogeneous clusters&amp;quot;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Focus on Outcome&lt;/strong&gt;: Include the intended benefit, such as &amp;quot;improved performance,&amp;quot; &amp;quot;enhanced scalability,&amp;quot; or &amp;quot;efficient resource utilization.&amp;quot;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Systems Focus&lt;/strong&gt;: Emphasize systems-level contributions (e.g., scheduler design, system integration) typical in OSDI, SOSP, or EuroSys papers.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="keep-it-concise"&gt;
&lt;h2&gt;4. Keep It Concise&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Length&lt;/strong&gt;: Aim for 8-15 words to balance detail and brevity, as longer titles may lose impact.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Avoid Redundancy&lt;/strong&gt;: Eliminate unnecessary words (e.g., &amp;quot;A Study on&amp;quot; or &amp;quot;Towards&amp;quot;) unless required by journal/conference guidelines.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Clarity Over Creativity&lt;/strong&gt;: Prioritize clarity over catchy phrases, as is standard in systems research.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="align-with-the-problem-statement"&gt;
&lt;h2&gt;5. Align with the Problem Statement&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: Ensure the title reflects the problem statement (e.g., addressing suboptimal scheduling in Kubernetes for ML workloads on heterogeneous clusters).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scope&lt;/strong&gt;: Match the scope of the aim and objectives (e.g., focus on scheduler extension, not general orchestration).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="follow-conference-journal-conventions"&gt;
&lt;h2&gt;6. Follow Conference/Journal Conventions&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Check Guidelines&lt;/strong&gt;: Review target venues (e.g., NSDI, ASPLOS, EuroSys) for title formatting preferences (e.g., capitalization, colons).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Style&lt;/strong&gt;: Use a descriptive or declarative style common in systems papers (e.g., &amp;quot;Optimizing X for Y&amp;quot; or &amp;quot;A System for Z&amp;quot;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Examples from Field&lt;/strong&gt;: Model after titles in top systems conferences, such as &amp;quot;Tiresias: A GPU Cluster Manager for Distributed Deep Learning&amp;quot; [NSDI 2020].&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="test-for-readability-and-appeal"&gt;
&lt;h2&gt;7. Test for Readability and Appeal&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Audience&lt;/strong&gt;: Ensure the title is understandable to systems researchers and practitioners familiar with Kubernetes and ML.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Feedback&lt;/strong&gt;: Share drafts with peers or mentors to confirm clarity and relevance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Searchability&lt;/strong&gt;: Test if the title includes keywords likely to be searched (e.g., &amp;quot;Kubernetes,&amp;quot; &amp;quot;heterogeneous,&amp;quot; &amp;quot;machine learning&amp;quot;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="avoid-overpromising"&gt;
&lt;h2&gt;8. Avoid Overpromising&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Be Realistic&lt;/strong&gt;: Don't claim overly broad impacts (e.g., &amp;quot;Revolutionizing Cloud Computing&amp;quot;) unless justified.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Focus on Contribution&lt;/strong&gt;: Emphasize the specific system or technique (e.g., scheduler extension) rather than vague goals.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="title-example"&gt;
&lt;h3&gt;Title Example&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&amp;quot;Optimizing Kubernetes Scheduling for Machine Learning Workloads on Heterogeneous CPU/GPU/TPU Clusters&amp;quot;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="discussion-of-the-example-title"&gt;
&lt;h2&gt;Discussion of the Example Title&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Clarity and Specificity&lt;/strong&gt;: The title clearly specifies the system (Kubernetes), the component (scheduling), the target application (machine learning workloads), and the context (heterogeneous CPU/GPU/TPU clusters).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Keywords&lt;/strong&gt;: Includes key terms like &amp;quot;Kubernetes,&amp;quot; &amp;quot;scheduling,&amp;quot; &amp;quot;machine learning,&amp;quot; &amp;quot;heterogeneous,&amp;quot; and &amp;quot;CPU/GPU/TPU&amp;quot; for discoverability in systems research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Novelty and Impact&lt;/strong&gt;: &amp;quot;Optimizing&amp;quot; suggests a performance-focused contribution, addressing the gap in inefficient pod placement for ML workloads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Conciseness&lt;/strong&gt;: At 10 words, it's brief yet descriptive, fitting within typical systems paper title lengths.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alignment with Problem Statement&lt;/strong&gt;: Reflects the problem statement's focus on suboptimal scheduling in Kubernetes for heterogeneous ML clusters, emphasizing performance and resource utilization.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Systems Convention&lt;/strong&gt;: Follows a descriptive style common in OSDI or NSDI papers (e.g., &amp;quot;Optimizing X for Y&amp;quot;) and avoids vague or overly broad terms.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="alternative-title-examples"&gt;
&lt;h2&gt;Alternative Title Examples&lt;/h2&gt;
&lt;p&gt;To illustrate flexibility, here are variations depending on emphasis:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;More Technical&lt;/strong&gt;: &lt;em&gt;&amp;quot;A Kubernetes Scheduler Extension for Heterogeneous ML Workload Optimization&amp;quot;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Broader Scope&lt;/strong&gt;: &lt;em&gt;&amp;quot;Efficient Scheduling for ML Workloads in Heterogeneous Kubernetes Clusters&amp;quot;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Specific Metric&lt;/strong&gt;: &lt;em&gt;&amp;quot;Low-Latency Kubernetes Scheduling for Heterogeneous ML Clusters&amp;quot;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="additional-tips-for-computer-systems-context"&gt;
&lt;h2&gt;Additional Tips for Computer Systems Context&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Reflect Systems Priorities&lt;/strong&gt;: Use terms like &amp;quot;optimizing,&amp;quot; &amp;quot;efficient,&amp;quot; or &amp;quot;scalable&amp;quot; to align with systems research goals (e.g., performance, scalability, resource efficiency).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reference the Platform&lt;/strong&gt;: Explicitly mentioning &amp;quot;Kubernetes&amp;quot; ensures relevance to cloud orchestration research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Highlight Application&lt;/strong&gt;: Including &amp;quot;machine learning workloads&amp;quot; ties to the growing importance of ML in systems research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Check Venue Fit&lt;/strong&gt;: For example, NSDI prefers titles emphasizing systems and networking, while ASPLOS may favor hardware-software integration (e.g., mentioning CPU/GPU/TPU).&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="acknowledgement"&gt;
&lt;h3&gt;Acknowledgement&lt;/h3&gt;
&lt;p&gt;This article was made with the help of Grok (accessed 2025-07-24)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Research Proposal"></category></entry><entry><title>Research Proposal Part 4: Writing the Review of Releated Literature</title><link href="https://srg-ics-uplb.github.io/blog/research-proposal-part-4-writing-the-review-of-releated-literature.html" rel="alternate"></link><published>2025-07-24T00:00:00+08:00</published><updated>2025-07-24T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2025-07-24:/blog/research-proposal-part-4-writing-the-review-of-releated-literature.html</id><summary type="html">&lt;p class="first last"&gt;The purpose of the review of related literature is to position your research, highlight the gap, demonstrate expertise, and provide context to your research.&lt;/p&gt;
</summary><content type="html">&lt;div class="section" id="purpose-of-the-review-of-related-literature-section"&gt;
&lt;h2&gt;Purpose of the Review of Related Literature Section&lt;/h2&gt;
&lt;p&gt;The review of related literature section serves to:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Position your research&lt;/strong&gt;: Show how your work builds on or differs from existing studies.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Highlight the gap&lt;/strong&gt;: Clearly articulate how existing solutions fall short, justifying your proposed research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Demonstrate expertise&lt;/strong&gt;: Prove your familiarity with the state-of-the-art in Computer Systems, particularly in Kubernetes, scheduling, and ML workloads for our running example.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Provide context&lt;/strong&gt;: For our running example, help readers understand the landscape of scheduling in heterogeneous systems.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="guidelines-for-writing-the-review"&gt;
&lt;h2&gt;Guidelines for Writing the Review&lt;/h2&gt;
&lt;p&gt;Specifics are for our running example.&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;strong&gt;Organize by Themes or Categories&lt;/strong&gt;: Group related work into logical categories (e.g., general Kubernetes scheduling, heterogeneous systems, ML workload optimization) to make the review structured and easy to follow.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Focus on Relevance&lt;/strong&gt;: Prioritize papers directly related to Kubernetes scheduling, heterogeneous hardware, and ML workloads. Include seminal works and recent advancements (within the last 3-5 years, i.e., 2020-2025).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Critically Analyze&lt;/strong&gt;: For each work, summarize its contributions, strengths, and limitations, &lt;em&gt;explicitly linking limitations to your research gap&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use Authoritative Sources&lt;/strong&gt;: Cite top-tier conference and journal papers (e.g., OSDI, SOSP, NSDI, EuroSys, ASPLOS) and relevant industry whitepapers or open-source documentation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Be Concise and Targeted&lt;/strong&gt;: Aim for 1-2 paragraphs per category, focusing on key works (6-10 papers total) to avoid overwhelming the reader.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Highlight Your Contribution&lt;/strong&gt;: Conclude by summarizing how your work addresses the gaps identified in the literature.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use Clear Citations&lt;/strong&gt;: Follow a consistent citation style (e.g., IEEE, ACM) and include DOIs or URLs for accessibility.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="practical-steps-for-writing"&gt;
&lt;h2&gt;Practical Steps for Writing&lt;/h2&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;strong&gt;Gather Sources&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;Search IEEE Xplore, ACM Digital Library, and arXiv for papers on Kubernetes scheduling, heterogeneous systems, and ML workloads (2020-2025).&lt;/li&gt;
&lt;li&gt;Check Kubernetes GitHub issues and documentation for practical insights.&lt;/li&gt;
&lt;li&gt;Monitor X for recent discussions (e.g., #Kubernetes, #MLSystems) to identify preprints or community critiques.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Organize and Summarize&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;Create a table or spreadsheet to track papers, their contributions, and limitations.&lt;/li&gt;
&lt;li&gt;Group papers into the three categories above (or adjust based on findings).&lt;/li&gt;
&lt;li&gt;Summarize each paper in 2-3 sentences, focusing on relevance to your gap.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Draft Critically&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;For each category, write a paragraph summarizing 2-3 key works, emphasizing their limitations.&lt;/li&gt;
&lt;li&gt;Use transitions to connect categories (e.g., &amp;quot;While Kubernetes schedulers address general workloads, they fall short in heterogeneous settings…&amp;quot;).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Synthesize and Conclude&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;Write a final paragraph that ties the limitations to your research gap and briefly previews your solution.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Revise for Clarity&lt;/strong&gt;:&lt;ul&gt;
&lt;li&gt;Ensure technical terms (e.g., pod, accelerator) are defined or clear from context.&lt;/li&gt;
&lt;li&gt;Verify citations are complete and follow the required style (e.g., [Author, Conference Year]).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="review-of-related-literature-example"&gt;
&lt;h2&gt;Review of Related Literature Example&lt;/h2&gt;
&lt;p&gt;For our running example, the review can be structured into three main subsections, each addressing a relevant aspect of the research gap, followed by a synthesis that ties the discussion to your proposed work. Shown below is a possible structure for the RRL.&lt;/p&gt;
&lt;div class="section" id="kubernetes-scheduling-frameworks"&gt;
&lt;h3&gt;&lt;em&gt;1. Kubernetes Scheduling Frameworks&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Objective&lt;/strong&gt;: Review existing Kubernetes scheduling mechanisms and their limitations for heterogeneous ML workloads.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;Example Discussion&lt;/strong&gt;:&lt;/dt&gt;
&lt;dd&gt;&lt;em&gt;Kubernetes, a widely adopted container orchestration platform, uses a default scheduler that employs a two-phase approach: filtering and scoring [Kubernetes Documentation, 2025]. The default scheduler prioritizes general-purpose metrics like CPU and memory availability but does not account for specialized hardware (e.g., GPUs, TPUs) or ML workload characteristics (e.g., data parallelism). Recent work, such as Firmament [Gog et al., SOSP 2019], integrates flow-based scheduling into Kubernetes, improving throughput for general workloads but lacking specific optimizations for heterogeneous accelerators. Similarly, Volcano [Volcano, 2024] supports batch scheduling for ML tasks but struggles with dynamic resource allocation in mixed CPU/GPU/TPU clusters, as noted in its GitHub issue tracker. These limitations highlight the need for a scheduler tailored to heterogeneous ML environments.&lt;/em&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="scheduling-for-heterogeneous-systems"&gt;
&lt;h3&gt;&lt;em&gt;2. Scheduling for Heterogeneous Systems&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Objective&lt;/strong&gt;: Analyze scheduling approaches in heterogeneous computing environments beyond Kubernetes.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;Example Discussion&lt;/strong&gt;:&lt;/dt&gt;
&lt;dd&gt;&lt;em&gt;Scheduling for heterogeneous systems has been explored in contexts like cloud computing and HPC. For instance, Tiresias [Gu et al., NSDI 2020] proposes a GPU cluster scheduler that optimizes for ML training jobs by predicting job duration and prioritizing short tasks. However, Tiresias assumes uniform GPU types and does not address TPU or mixed-accelerator scenarios. Another work, Themis [Mahajan et al., ASPLOS 2021], introduces fairness-aware scheduling for GPU clusters but incurs high overhead in multi-tenant settings with diverse hardware. These approaches, while effective for specific accelerators, do not generalize to Kubernetes clusters with mixed CPU/GPU/TPU nodes, leaving a gap in flexible, hardware-aware scheduling.&lt;/em&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="optimization-for-ml-workloads"&gt;
&lt;h3&gt;&lt;em&gt;3. Optimization for ML Workloads&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Objective&lt;/strong&gt;: Examine systems designed for ML workload optimization, focusing on their scheduling limitations.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;Example Discussion&lt;/strong&gt;:&lt;/dt&gt;
&lt;dd&gt;&lt;em&gt;ML workloads, such as deep learning training and inference, impose unique demands on system resources. Systems like Allox [Kaur et al., EuroSys 2023] optimize resource allocation for ML jobs in cloud environments by modeling workload dependencies but are not integrated with Kubernetes. Similarly, Google's Borg scheduler [Verma et al., EuroSys 2015] supports large-scale ML workloads but is proprietary and not optimized for open-source platforms like Kubernetes. Recent studies [Wang et al., OSDI 2024] highlight that ML workloads on heterogeneous clusters suffer from resource contention and suboptimal placement due to a lack of hardware-aware scheduling policies. This underscores the need for a Kubernetes-native solution tailored to ML workload demands.&lt;/em&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class="section" id="synthesis-and-gap-identification"&gt;
&lt;h3&gt;&lt;em&gt;4. Synthesis and Gap Identification&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Objective&lt;/strong&gt;: Summarize the limitations of existing work and position your research as a solution.&lt;/p&gt;
&lt;dl class="docutils"&gt;
&lt;dt&gt;&lt;strong&gt;Example Discussion&lt;/strong&gt;:&lt;/dt&gt;
&lt;dd&gt;&lt;em&gt;Existing Kubernetes schedulers, such as the default scheduler and Volcano, are designed for general-purpose or batch workloads but lack fine-grained support for heterogeneous hardware and ML-specific requirements. While systems like Tiresias and Themis address GPU scheduling, they do not generalize to mixed CPU/GPU/TPU clusters or integrate with Kubernetes. Furthermore, ML workload optimizations, as seen in Allox, are not designed for containerized environments. Our work addresses these gaps by proposing a Kubernetes scheduler extension that optimizes pod placement for ML workloads on heterogeneous clusters, improving performance, resource utilization, and scalability.&lt;/em&gt;&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="section" id="tips-for-computer-systems-context"&gt;
&lt;h2&gt;Tips for Computer Systems Context&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Emphasize Systems Metrics&lt;/strong&gt;: Discuss how existing works measure performance (e.g., throughput, latency, resource utilization) and where they fall short for ML workloads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Address Practicality&lt;/strong&gt;: Highlight gaps in real-world applicability, especially for open-source platforms like Kubernetes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consider Scalability and Robustness&lt;/strong&gt;: Note limitations in handling large-scale or failure-prone clusters, as these are critical in systems research.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Stay Current&lt;/strong&gt;: Use recent papers (2020-2025) and check preprints on arXiv or discussions on X to ensure your review reflects the latest trends.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next post will focus on the &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-5-writing-the-title.html"&gt;Title&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="acknowledgement"&gt;
&lt;h2&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;This article was made with the help of Grok (accessed 2025-07-24)&lt;/p&gt;
&lt;/div&gt;
</content><category term="Research Proposal"></category></entry><entry><title>Research Proposal Part 3: Writing the Aim, Objectives, and Methods</title><link href="https://srg-ics-uplb.github.io/blog/research-proposal-part-3-writing-the-aim-objectives-and-methods.html" rel="alternate"></link><published>2025-07-23T00:00:00+08:00</published><updated>2025-07-23T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2025-07-23:/blog/research-proposal-part-3-writing-the-aim-objectives-and-methods.html</id><summary type="html">&lt;p class="first last"&gt;The Aims, Objectives, and Methods should be clearly articulated as this is what the researcher is set to achieve for the research.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;Once a research gap has been identified and Problem Statement has been drafted, the Aim, Objectives, and Methods can now be written. Below is a short discussion on how to write the Aim, Objectives, and Methods for a research proposal based on the example from &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-1-finding-and-identifying-research-gaps.html"&gt;Approach 5: Analyzing real-world systems and industry needs&lt;/a&gt;. The example identified a research gap in &lt;em&gt;developing a Kubernetes scheduler extension that optimizes for heterogeneous hardware in ML-heavy clusters&lt;/em&gt;, inspired by unresolved issues in the Kubernetes GitHub tracker about inefficient pod scheduling on mixed CPU/GPU/TPU nodes.&lt;/p&gt;
&lt;p&gt;When crafting a research proposal for this gap, the Aim, Objectives, and Methods sections should clearly articulate the purpose, specific goals, and approach to addressing the problem. These sections must be concise, focused, and aligned with the identified gap, ensuring the research is feasible and impactful in the context of Computer Systems.&lt;/p&gt;
&lt;div class="section" id="aim-aka-general-objective"&gt;
&lt;h2&gt;1. Aim (aka General Objective)&lt;/h2&gt;
&lt;p&gt;The Aim is a single, high-level statement that captures the overall purpose of the research. It should directly address the research gap and highlight the intended contribution to the field.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Guidelines&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Be specific about the problem (inefficient scheduling in Kubernetes for heterogeneous ML clusters).&lt;/li&gt;
&lt;li&gt;Emphasize the desired outcome (improved performance, resource utilization, or fairness).&lt;/li&gt;
&lt;li&gt;Keep it concise (1–2 sentences) and avoid technical jargon to ensure clarity.&lt;/li&gt;
&lt;li&gt;Align with the gap’s real-world relevance (e.g., supporting machine learning workloads).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example Aim&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The aim of this research is to develop a Kubernetes scheduler extension that optimizes pod placement for machine learning workloads on heterogeneous clusters, enhancing performance and resource utilization.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="specific-objectives"&gt;
&lt;h2&gt;2. (Specific) Objectives&lt;/h2&gt;
&lt;p&gt;The Objectives break down the aim into specific, measurable, and achievable goals. They should outline the key steps or outcomes needed to address the research gap.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Guidelines&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Use actionable verbs (e.g., design, evaluate, implement) to describe what will be achieved.&lt;/li&gt;
&lt;li&gt;Ensure objectives are SMART (Specific, Measurable, Achievable, Relevant, Time-bound).&lt;/li&gt;
&lt;li&gt;Cover both technical (e.g., algorithm design) and evaluative (e.g., performance analysis) aspects.&lt;/li&gt;
&lt;li&gt;Typically, include 3–5 objectives to keep the scope manageable.&lt;/li&gt;
&lt;li&gt;Reflect the systems-specific context (e.g., handling GPUs/TPUs, improving ML workload efficiency).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example Objectives&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Specifically, this study intends to:&lt;/em&gt;&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;em&gt;design a scheduling algorithm that accounts for heterogeneous hardware (CPU, GPU, TPU) characteristics in Kubernetes clusters;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;implement the proposed scheduler extension as a pluggable module in the Kubernetes framework;&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;evaluate the scheduler’s performance in terms of throughput, latency, and resource utilization for ML workloads compared to the default Kubernetes scheduler; and&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;assess the scheduler’s scalability and robustness under diverse ML workloads and cluster configurations.&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class="section" id="methods"&gt;
&lt;h2&gt;3. Methods&lt;/h2&gt;
&lt;p&gt;The Methods section describes the technical approach to achieving the objectives. It should provide a clear, logical plan for designing, implementing, and evaluating the solution, tailored to the Computer Systems domain.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Guidelines&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Outline the key steps: algorithm design, implementation, experimentation, and evaluation.&lt;/li&gt;
&lt;li&gt;Specify tools, platforms, or frameworks (e.g., Kubernetes, ML benchmarks like MLPerf).&lt;/li&gt;
&lt;li&gt;Describe the experimental setup, including hardware (e.g., heterogeneous clusters) and metrics (e.g., throughput, latency).&lt;/li&gt;
&lt;li&gt;Address how the methods tackle the gap (e.g., optimizing for heterogeneous hardware).&lt;/li&gt;
&lt;li&gt;Ensure feasibility by leveraging existing tools and datasets where possible.&lt;/li&gt;
&lt;li&gt;Include validation or comparison against baselines (e.g., default Kubernetes scheduler).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example Methods&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;To address the identified gap, the research will proceed as follows:&lt;/em&gt;&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;em&gt;Algorithm Design: Develop a scheduling algorithm that incorporates hardware-specific metrics (e.g., GPU memory bandwidth, TPU compute capacity) and ML workload requirements (e.g., data parallelism, model size). The algorithm will use a weighted scoring model to prioritize pod placement based on resource compatibility and workload demands.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Implementation: Implement the scheduler as a custom Kubernetes scheduler extension using Go, integrated with the Kubernetes API. The extension will leverage kube-scheduler’s pluggable architecture to ensure compatibility with existing clusters.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Experimental Setup: Deploy a testbed cluster with mixed CPU (Intel Xeon), GPU (NVIDIA A100), and TPU (Google Cloud TPU v4) nodes using a cloud provider like Google Kubernetes Engine (GKE). Use ML workloads from MLPerf (e.g., ResNet, BERT) to simulate real-world scenarios.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Evaluation: Compare the proposed scheduler against the default Kubernetes scheduler and state-of-the-art alternatives (e.g., Volcano). Measure key metrics: (a) throughput (tasks completed per second), (b) latency (task completion time), (c) resource utilization (CPU/GPU/TPU usage), and (d) scheduling overhead. Conduct experiments under varying cluster sizes (4–16 nodes) and workload intensities.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Validation: Analyze results to confirm improvements in performance and scalability, and validate robustness by introducing synthetic failures (e.g., node crashes) to test fault tolerance.&lt;/em&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="section" id="discussion"&gt;
&lt;h3&gt;Discussion&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Aim&lt;/strong&gt;: The example aim is concise and directly targets the gap by focusing on optimizing Kubernetes scheduling for heterogeneous ML clusters. It emphasizes practical impact (performance, resource utilization), which is critical for industry adoption.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Objectives&lt;/strong&gt;: The objectives break the aim into actionable steps, covering design, implementation, and evaluation. They are specific (e.g., handling CPU/GPU/TPU) and measurable (e.g., throughput, latency), ensuring the research is focused and achievable within a typical systems project timeline.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Methods&lt;/strong&gt;: The methods provide a clear roadmap, leveraging existing tools (Kubernetes, MLPerf, GKE) to ensure feasibility. The experimental setup reflects real-world ML cluster scenarios, and the comparison with baselines (default scheduler, Volcano) strengthens the evaluation. The inclusion of fault tolerance testing aligns with systems research priorities like robustness.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next post will focus on the &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-4-writing-the-review-of-releated-literature.html"&gt;Review of Related Literature&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="acknowledgement"&gt;
&lt;h3&gt;Acknowledgement&lt;/h3&gt;
&lt;p&gt;This article was made with the help of Grok (accessed 2025-07-23)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Research Proposal"></category></entry><entry><title>Research Proposal Part 2: Writing the Problem Statement</title><link href="https://srg-ics-uplb.github.io/blog/research-proposal-part-2-writing-the-problem-statement.html" rel="alternate"></link><published>2025-07-22T00:00:00+08:00</published><updated>2025-07-22T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2025-07-22:/blog/research-proposal-part-2-writing-the-problem-statement.html</id><summary type="html">&lt;p&gt;Once a research gap has been identified, a Problem Statement can be created. Below is a short discussion on how to write the Problem Statement for a research proposal based on the example from &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-1-finding-and-identifying-research-gaps.html"&gt;Approach        5: Analyzing real-world systems and industry needs&lt;/a&gt;. The example identified a research gap in &lt;em&gt;developing …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Once a research gap has been identified, a Problem Statement can be created. Below is a short discussion on how to write the Problem Statement for a research proposal based on the example from &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-1-finding-and-identifying-research-gaps.html"&gt;Approach        5: Analyzing real-world systems and industry needs&lt;/a&gt;. The example identified a research gap in &lt;em&gt;developing a Kubernetes scheduler extension that optimizes for heterogeneous hardware in ML-hea       vy clusters&lt;/em&gt;, inspired by unresolved issues in the Kubernetes GitHub tracker about inefficient pod scheduling on mixed CPU/GPU/TPU nodes.&lt;/p&gt;
&lt;div class="section" id="define-the-problem-clearly"&gt;
&lt;h2&gt;1. Define the Problem Clearly&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;What is the issue?&lt;/strong&gt; Specify the core limitation or deficiency in existing systems (e.g., inefficient scheduling for heterogeneous ML clusters).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Context&lt;/strong&gt;: Provide enough background to make the problem understandable to both experts and non-experts in Computer Systems.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scope&lt;/strong&gt;: Narrow the focus to the specific domain (Kubernetes, heterogeneous clusters, ML workloads) to avoid being overly broad.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="highlight-the-impact"&gt;
&lt;h2&gt;2. Highlight the Impact&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Why is it significant?&lt;/strong&gt; Explain the consequences of the gap (e.g., poor performance, wasted resources, limited scalability).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Who is affected?&lt;/strong&gt; Identify stakeholders (e.g., cloud providers, ML practitioners, DevOps engineers).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Real-world relevance&lt;/strong&gt;: Connect to practical scenarios, such as deploying ML models in production environments.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="justify-the-need-for-a-solution"&gt;
&lt;h2&gt;3. Justify the Need for a Solution&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Why hasn't it been solved?&lt;/strong&gt; Reference limitations in existing work (e.g., lack of hardware-aware scheduling, poor integration with Kubernetes).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Why now?&lt;/strong&gt; Emphasize current trends (e.g., increasing adoption of heterogeneous accelerators, growing demand for ML in cloud environments).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Feasibility&lt;/strong&gt;: Suggest that the problem is tractable with current tools and expertise.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="frame-as-a-research-problem"&gt;
&lt;h2&gt;4. Frame as a Research Problem&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Structure&lt;/strong&gt;: Combine the issue, its impact, and the need for a solution into a concise statement (1-2 sentences).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Tone&lt;/strong&gt;: Use precise, formal language suitable for a research proposal, avoiding vague terms like &amp;quot;better&amp;quot; or &amp;quot;improved&amp;quot; without context.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alignment&lt;/strong&gt;: Ensure the statement directly ties to the research gap and sets up the aim and objectives of your study.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="validate-the-statement"&gt;
&lt;h2&gt;5. Validate the Statement&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Specificity&lt;/strong&gt;: Does it clearly address the gap (heterogeneous ML scheduling in Kubernetes)?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Relevance&lt;/strong&gt;: Does it connect to current challenges in Computer Systems?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Actionability&lt;/strong&gt;: Does it suggest a research direction (e.g., designing a new scheduler)?&lt;/li&gt;
&lt;/ul&gt;
&lt;div class="section" id="example-problem-statement"&gt;
&lt;h3&gt;Example Problem Statement&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;&amp;quot;The default Kubernetes scheduler and existing alternatives, such as Volcano, lack fine-grained support for optimizing pod placement on heterogeneous clusters comprising CPUs, GPUs, and TPUs, resulting in suboptimal performance, resource underutilization, and limited scalability for machine learning workloads. As the adoption of heterogeneous accelerators and ML-driven applications grows in cloud environments, there is an urgent need for a Kubernetes-native scheduling solution that effectively leverages diverse hardware to meet the performance and efficiency demands of modern ML workflows.&amp;quot;&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="discussion-of-the-example"&gt;
&lt;h3&gt;Discussion of the Example&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Clarity&lt;/strong&gt;: The problem statement specifies the issue (lack of fine-grained scheduling support for heterogeneous clusters) and the context (Kubernetes, ML workloads).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Impact&lt;/strong&gt;: It highlights consequences (suboptimal performance, resource underutilization, limited scalability) and stakeholders (cloud providers, ML practitioners).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Need&lt;/strong&gt;: It underscores the urgency due to trends (growing use of heterogeneous accelerators, ML adoption) and implies the gap is unaddressed by referencing limitations in existing schedulers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alignment with Gap&lt;/strong&gt;: The statement directly reflects the research gap, focusing on the need for a Kubernetes-native, hardware-aware scheduler for ML workloads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Research Framing&lt;/strong&gt;: It sets up the proposed research (a new scheduler) without prescribing the solution, leaving room for the &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-3-writing-the-aim-objectives-and-methods.html"&gt;aim and objectives&lt;/a&gt; to elaborate.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class="section" id="tips-for-computer-systems-context"&gt;
&lt;h3&gt;Tips for Computer Systems Context&lt;/h3&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Emphasize Systems Metrics&lt;/strong&gt;: Include terms like &amp;quot;performance,&amp;quot; &amp;quot;resource utilization,&amp;quot; or &amp;quot;scalability&amp;quot; to align with systems research priorities.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ground in Practicality&lt;/strong&gt;: Reference real-world platforms (e.g., Kubernetes) and workloads (e.g., ML) to make the problem relevant to industry and academia.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Leverage Trends&lt;/strong&gt;: Tie the problem to current technological shifts, such as the rise of TPUs or edge computing, to justify timeliness.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Be Concise&lt;/strong&gt;: Aim for 1-2 sentences to maintain focus, as seen in the example.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next post will focus on the &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-3-writing-the-aim-objectives-and-methods.html"&gt;Aims, Objectives, and Methods&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="acknowledgement"&gt;
&lt;h3&gt;Acknowledgement&lt;/h3&gt;
&lt;p&gt;This article was made with the help of Grok (accessed 2025-07-22)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="Research Proposal"></category></entry><entry><title>Research Proposal Part 1: Finding and Identifying Research Gaps</title><link href="https://srg-ics-uplb.github.io/blog/research-proposal-part-1-finding-and-identifying-research-gaps.html" rel="alternate"></link><published>2025-07-21T00:00:00+08:00</published><updated>2025-07-24T00:00:00+08:00</updated><author><name>Joseph Anthony C. Hermocilla</name></author><id>tag:srg-ics-uplb.github.io,2025-07-21:/blog/research-proposal-part-1-finding-and-identifying-research-gaps.html</id><summary type="html">&lt;p class="first last"&gt;A series of posts to help students come up with a research proposal for their CMSC 190/200/300 or for publication in conferences and journals. I used AI tools to create these posts, Grok in particular.&lt;/p&gt;
</summary><content type="html">&lt;img alt="" class="align-center" src="./images/jach/008_gaps.png" style="width: 50%;" /&gt;
&lt;p&gt;A research endeavor usually starts by identifying research gaps. A research gap is 'something' (question, concept, approach)
within a research area that has not been answered or addressed yet and thus have limited discussion in the
literature. In this post, some approaches (with techniques and examples) to find and identify research gaps in computer systems research are presented.&lt;/p&gt;
&lt;div class="section" id="conduct-a-comprehensive-literature-review"&gt;
&lt;h2&gt;1. Conduct a Comprehensive Literature Review&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Understand the state-of-the-art and identify areas that are underexplored or unresolved.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Systematic Search&lt;/strong&gt;: Use academic databases like IEEE Xplore, ACM Digital Library, Springer, arXiv, and Google Scholar to search for recent papers, surveys, and reviews in your subfield (e.g., cloud computing, storage systems, or machine learning systems).&lt;ul&gt;
&lt;li&gt;Use specific keywords (e.g., “energy-efficient computing,” “scalable distributed systems”) and combine them with Boolean operators (AND, OR, NOT) to refine results.&lt;/li&gt;
&lt;li&gt;Filter for recent publications (last 3–5 years) to focus on current trends.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Read Survey Papers and Reviews&lt;/strong&gt;: Surveys often summarize open challenges and future directions explicitly. For example, look for “Open Problems” or “Future Work” sections in journals like &lt;em&gt;ACM Computing Surveys&lt;/em&gt; or &lt;em&gt;IEEE Transactions&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Analyze Highly Cited Papers&lt;/strong&gt;: Identify foundational papers and check their “Future Work” sections or limitations to uncover unresolved issues.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Track Emerging Topics&lt;/strong&gt;: Monitor proceedings of top conferences (e.g., OSDI, SOSP, ASPLOS, ISCA, USENIX ATC) to spot new trends or areas with limited follow-up work.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: While reviewing IEEE Xplore for papers on distributed storage systems, you find a 2024 survey in ACM Computing Surveys on “Next-Generation Storage Systems.” The survey highlights that current systems like Ceph and HDFS are optimized for large-scale cloud environments but lack efficient support for geo-distributed edge storage with intermittent connectivity. The “Future Work” section suggests exploring decentralized storage protocols for edge environments, but no follow-up papers address this. &lt;em&gt;Gap&lt;/em&gt;: Designing a distributed storage system tailored for edge devices with unreliable network conditions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Pay attention to performance bottlenecks, scalability limitations, or security vulnerabilities mentioned in system evaluations, as these often point to gaps.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="identify-limitations-in-existing-work"&gt;
&lt;h2&gt;2. Identify Limitations in Existing Work&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Pinpoint weaknesses or constraints in current systems or methodologies that your research can address.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Scrutinize Evaluation Sections&lt;/strong&gt;: Look at how systems are evaluated (e.g., benchmarks, workloads, or metrics). Are there scenarios where the system underperforms?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Examine Assumptions&lt;/strong&gt;: Many systems papers make simplifying assumptions (e.g., homogeneous hardware, idealized network conditions). Gaps often exist where these assumptions don’t hold.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Check Scalability and Applicability&lt;/strong&gt;: Investigate if current solutions scale to emerging technologies or fail under new constraints.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Look for Trade-offs&lt;/strong&gt;: Gaps may lie in optimizing trade-offs or mitigating their downsides.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: A 2023 OSDI paper on a new memory management system for cloud servers assumes homogeneous memory latency across NUMA nodes. Its evaluation shows performance degradation when applied to disaggregated memory systems (e.g., where memory is accessed over a network). &lt;em&gt;Gap&lt;/em&gt;: Developing memory management techniques that optimize for disaggregated memory architectures with variable latency.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Focus on practical deployment gaps—e.g., systems that work well in labs but not in real-world environments.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="engage-with-the-research-community"&gt;
&lt;h2&gt;3. Engage with the Research Community&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Leverage discussions and feedback from experts to uncover less-visible gaps.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Attend conferences and workshops (e.g., NSDI, EuroSys, HotOS).&lt;/li&gt;
&lt;li&gt;Join mailing lists and forums (e.g., ACM SIGOPS or SIGARCH).&lt;/li&gt;
&lt;li&gt;Collaborate and network with peers or practitioners.&lt;/li&gt;
&lt;li&gt;Follow posts from researchers or organizations on platforms like X.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: At SOSP 2025, during a panel on “Systems for AI Workloads,” a researcher mentions that current GPU scheduling frameworks (e.g., NVIDIA’s MPS) struggle with dynamic multi-tenant AI workloads due to poor isolation and resource contention. No solutions are proposed in the discussion. &lt;em&gt;Gap&lt;/em&gt;: Creating a GPU scheduling framework that ensures strong isolation and fairness for multi-tenant AI inference in data centers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Collaborate with industry to find real-world deployment gaps.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="explore-interdisciplinary-and-emerging-areas"&gt;
&lt;h2&gt;4. Explore Interdisciplinary and Emerging Areas&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Identify gaps at the intersection of systems and other domains or new trends.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Analyze cross-disciplinary interactions (e.g., with ML, IoT, or crypto).&lt;/li&gt;
&lt;li&gt;Monitor emerging technologies (e.g., TPUs, serverless, disaggregated memory).&lt;/li&gt;
&lt;li&gt;Examine application domains (e.g., AR/VR, autonomous vehicles).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: While exploring the intersection of Computer Systems and quantum computing, you notice that existing operating systems lack support for scheduling hybrid classical-quantum workloads. Papers on quantum computing focus on algorithms but not on system-level integration with classical hardware. &lt;em&gt;Gap&lt;/em&gt;: Designing an operating system scheduler that optimizes resource allocation for hybrid quantum-classical computing environments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Gaps often arise when adapting systems to new use cases or hardware.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="analyze-real-world-systems-and-industry-needs"&gt;
&lt;h2&gt;5. Analyze Real-World Systems and Industry Needs&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Ground your research in real-world issues.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Study open-source systems and issues (e.g., Linux, Kubernetes).&lt;/li&gt;
&lt;li&gt;Read technical industry reports (e.g., Spanner, DynamoDB).&lt;/li&gt;
&lt;li&gt;Monitor news or posts about outages, bugs, or breaches.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: Analyzing the Kubernetes GitHub issue tracker, you find multiple unresolved issues about inefficient pod scheduling on heterogeneous clusters with mixed CPU/GPU/TPU nodes. Users report suboptimal performance for machine learning workloads. &lt;em&gt;Gap&lt;/em&gt;: Developing a Kubernetes scheduler extension that optimizes for heterogeneous hardware in ML-heavy clusters.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Look for practical challenges like energy, cost, and maintainability.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="leverage-quantitative-and-qualitative-analysis"&gt;
&lt;h2&gt;6. Leverage Quantitative and Qualitative Analysis&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Use structured methods to find gaps.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Use SWOT or other gap analysis frameworks.&lt;/li&gt;
&lt;li&gt;Build taxonomies of existing work.&lt;/li&gt;
&lt;li&gt;Benchmark current systems.&lt;/li&gt;
&lt;li&gt;Survey experts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: You create a taxonomy of existing fault-tolerance mechanisms in distributed systems (e.g., checkpointing, replication, erasure coding). You notice that most mechanisms are designed for crash failures but not for Byzantine failures in large-scale systems. A benchmark you run on Apache Spark reveals high overhead when handling Byzantine faults. &lt;em&gt;Gap&lt;/em&gt;: Designing lightweight Byzantine fault-tolerant protocols for large-scale distributed data processing systems.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Quantitative analysis of metrics (e.g., latency, energy) can highlight performance gaps.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="focus-on-future-work-and-open-questions"&gt;
&lt;h2&gt;7. Focus on “Future Work” and Open Questions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Mine existing research for explicitly stated gaps.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Collect “Future Work” sections across papers.&lt;/li&gt;
&lt;li&gt;Look for speculative or abandoned ideas.&lt;/li&gt;
&lt;li&gt;Find threads in older papers that remain unresolved.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: A 2024 ASPLOS paper on serverless computing platforms notes that current platforms (e.g., AWS Lambda) struggle with cold-start latency for latency-sensitive applications like real-time video processing. The “Future Work” section suggests exploring predictive pre-warming but lacks implementation details. &lt;em&gt;Gap&lt;/em&gt;: Developing a predictive pre-warming mechanism to reduce cold-start latency in serverless platforms for real-time applications.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Common themes include scalability and portability issues.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="experiment-and-prototype"&gt;
&lt;h2&gt;8. Experiment and Prototype&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Use experimentation to uncover practical gaps.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Build proof-of-concepts.&lt;/li&gt;
&lt;li&gt;Stress-test existing systems.&lt;/li&gt;
&lt;li&gt;Simulate future scenarios.&lt;/li&gt;
&lt;li&gt;Reproduce prior work.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: You prototype a distributed file system based on a recent NSDI paper and test it under high-latency network conditions (e.g., simulating 5G edge networks). The system exhibits significant performance degradation due to its reliance on synchronous replication. &lt;em&gt;Gap&lt;/em&gt;: Designing an asynchronous replication protocol that maintains consistency in high-latency edge environments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Prototyping reveals practical limitations (e.g., complexity, compatibility).&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="stay-updated-with-real-time-information"&gt;
&lt;h2&gt;9. Stay Updated with Real-Time Information&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Ensure your gap analysis is current.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Search X for discussions or trending research hashtags.&lt;/li&gt;
&lt;li&gt;Monitor arXiv or preprint platforms.&lt;/li&gt;
&lt;li&gt;Watch funding agency calls (e.g., NSF, DARPA).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: On X, a systems researcher (&amp;#64;SysProf2025) posts about a recent arXiv preprint on secure enclaves (e.g., Intel SGX, AMD SEV). The discussion highlights that enclaves are vulnerable to side-channel attacks in multi-tenant cloud environments, with no robust mitigation for dynamic workloads. &lt;em&gt;Gap&lt;/em&gt;: Developing a secure enclave framework that mitigates side-channel attacks in multi-tenant cloud settings.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Real-time debates can signal overhyped or unworkable approaches.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="reflect-on-your-own-expertise-and-interests"&gt;
&lt;h2&gt;10. Reflect on Your Own Expertise and Interests&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Match research gaps to your skills and interests.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Techniques&lt;/strong&gt;:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;Map your expertise and look for domain-specific gaps.&lt;/li&gt;
&lt;li&gt;Brainstorm new applications for familiar techniques.&lt;/li&gt;
&lt;li&gt;Revisit your own past work for extensions or limitations.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: As an expert in computer architecture, you revisit your prior work on cache coherence protocols for multi-core CPUs. You realize that existing protocols are not optimized for emerging chiplet-based architectures, where cores are physically disaggregated. &lt;em&gt;Gap&lt;/em&gt;: Designing a cache coherence protocol tailored for chiplet-based processors to improve performance and energy efficiency.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Tip for Computer Systems&lt;/strong&gt;: Your unique viewpoint can spot overlooked gaps.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="practical-steps-to-validate-a-research-gap"&gt;
&lt;h2&gt;Practical Steps to Validate a Research Gap&lt;/h2&gt;
&lt;p&gt;Once you identify a potential gap:&lt;/p&gt;
&lt;ol class="arabic simple"&gt;
&lt;li&gt;&lt;strong&gt;Novelty Check&lt;/strong&gt;: Ensure no recent work has addressed it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Impact Assessment&lt;/strong&gt;: Evaluate real-world or academic importance.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Feasibility Analysis&lt;/strong&gt;: Check tools, data, and time constraints.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Community Feedback&lt;/strong&gt;: Get input from peers and mentors.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The above tasks can be done with your adviser and mentors.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="final-tips"&gt;
&lt;h2&gt;Final Tips&lt;/h2&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;strong&gt;Document Your Process&lt;/strong&gt;: Maintain a gap-tracking notebook or database.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Iterate Continuously&lt;/strong&gt;: Revisit gaps as literature and tech evolve.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Balance Novelty and Feasibility&lt;/strong&gt;: Choose problems that are new &lt;em&gt;and&lt;/em&gt; solvable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next post will focus on the &lt;a class="reference external" href="https://srg-ics-uplb.github.io/blog/research-proposal-part-2-writing-the-problem-statement.html"&gt;Problem Statement&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="acknowledgement"&gt;
&lt;h2&gt;Acknowledgement&lt;/h2&gt;
&lt;p&gt;This article was made with the help of Grok (accessed 2025-07-21)&lt;/p&gt;
&lt;/div&gt;
</content><category term="Research Proposal"></category></entry></feed>